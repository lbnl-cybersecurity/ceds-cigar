{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "C:\\Users\\Sy-Toan\\ceds-cigar\\LBNL_Simulations\\testpvnum10\\node_1_pv_10_minute.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6431dc00b8f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mFileDirectoryExtenstion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'node_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_pv_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPV_Feeder_model\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_minute.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mFileName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFileDirectoryBase\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFileDirectoryExtenstion\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mMatFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFileName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0mQSTS_Data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLoadList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMatFile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[0;32m   1682\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1684\u001b[1;33m             \u001b[0mfhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1685\u001b[0m             \u001b[0mown_fhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    614\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    615\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: C:\\Users\\Sy-Toan\\ceds-cigar\\LBNL_Simulations\\testpvnum10\\node_1_pv_10_minute.csv not found."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import tan,acos\n",
    "import os\n",
    "import matlab\n",
    "import matlab.engine\n",
    "def start_matlab():\n",
    "    return matlab.engine.start_matlab()\n",
    "def quit_matlab(matlab_engine):\n",
    "    matlab_engine.quit()\n",
    "    \n",
    "def ieee_feeder_mapper(matlab_engine, IeeeFeeder):\n",
    "    FeederMap, Z_in_ohm, Paths, NodeList, LoadList = matlab_engine.ieee_feeder_mapper(IeeeFeeder, nargout=5)\n",
    "    FeederMap = np.array(FeederMap)\n",
    "    Z_in_ohm = np.array(Z_in_ohm)\n",
    "    Paths = np.array(Paths)\n",
    "    NodeList = np.array(NodeList)\n",
    "    LoadList = np.array(LoadList)\n",
    "    return FeederMap, Z_in_ohm, Paths, NodeList[0], LoadList[0]-1\n",
    "\n",
    "def FBSfun(matlab_engine, V0, loads, Z, B):\n",
    "    V, _, S, _ = matlab_engine.FBSfun(float(V0), matlab.double(loads.tolist(),is_complex=True), matlab.double(Z.tolist(), is_complex=True), matlab.double(B.tolist(),is_complex=True), nargout=4)\n",
    "    V = np.array(V, dtype=np.complex).squeeze()\n",
    "    S = np.array(S, dtype=np.complex).squeeze()\n",
    "    return V, S\n",
    "\n",
    "IeeeFeeder = 13\n",
    "matlab_engine = start_matlab()  \n",
    "\n",
    "LoadScalingFactor=2000\n",
    "GenerationScalingFactor=50\n",
    "SlackBusVoltage=1.02\n",
    "power_factor=0.9\n",
    "IncludeSolar=1\n",
    "\n",
    "#Feeder parameters\n",
    "\n",
    "LineNames = ('l_632_633','l_632_645','l_632_671','l_633_634','l_645_646','l_650_632','l_671_680','l_671_684',\n",
    "             'l_671_692','l_684_611','l_684_652','l_692_675','l_u_650')\n",
    "\n",
    "AllBusNames = ('sourcebus',\n",
    "               'load_611','load_634','load_645','load_646','load_652','load_671','load_675','load_692',\n",
    "               'bus_611','bus_634','bus_645','bus_646','bus_652','bus_671','bus_675','bus_692','bus_632',\n",
    "               'bus_633','bus_650','bus_680','bus_684')\n",
    "\n",
    "LoadBusNames = AllBusNames[1:9]\n",
    "BusNames = AllBusNames[9:22]\n",
    "IeeeFeeder = 13\n",
    "\n",
    "LoadList = np.array([6,7,8,13,3,12,11,10])-1\n",
    "NodeList = np.array([650,632,671,680,633,634,645,646,684,611,692,675,652])\n",
    "BusesWithControl = NodeList[LoadList]\n",
    "\n",
    "NumberOfLoads=len(LoadBusNames)\n",
    "NumberOfNodes=len(BusNames)\n",
    "\n",
    "FeederMap, Z_in_ohm, Paths, _, _ = ieee_feeder_mapper(matlab_engine, IeeeFeeder)\n",
    "\n",
    "#Base value calculation\n",
    "Vbase = 4.16e3 #4.16 kV\n",
    "Sbase = 1.0 #500 kVA\n",
    "Zbase = Vbase**2/Sbase\n",
    "Ibase = Sbase/Vbase\n",
    "Z = Z_in_ohm/Zbase\n",
    "\n",
    "#Load Data Pertaining to Loads to create a profile\n",
    "PV_Feeder_model = 10\n",
    "FileDirectoryBase = 'C:\\\\Users\\\\Toan Ngo\\\\Documents\\\\GitHub\\\\ceds-cigar\\\\LBNL_Simulations\\\\testpvnum10\\\\'\n",
    "Time = list(range(1441))\n",
    "TotalTimeSteps = len(Time)\n",
    "QSTS_Data = np.zeros((TotalTimeSteps,4,IeeeFeeder))\n",
    "for node in range(NumberOfLoads):\n",
    "    FileDirectoryExtenstion = 'node_' + str(node+1) + '_pv_' + str(PV_Feeder_model) + '_minute.csv'\n",
    "    FileName = FileDirectoryBase + FileDirectoryExtenstion\n",
    "    MatFile = np.genfromtxt(FileName, delimiter=',')\n",
    "    QSTS_Data[:,:,int(LoadList[node])] = MatFile\n",
    "\n",
    "#Seperate PV Generation Data\n",
    "Generation = QSTS_Data[:,1,:]*GenerationScalingFactor\n",
    "Load = QSTS_Data[:,3,:]*LoadScalingFactor\n",
    "Generation = np.squeeze(Generation)/Sbase\n",
    "Load = np.squeeze(Load)/Sbase\n",
    "MaxGenerationPossible = np.max(Generation, axis=0)\n",
    "\n",
    "#Voltage Observer Parameters and related variable initialization\n",
    "LowPassFilterFrequency = 0.1\n",
    "HighPassFilterFrequency = 1.0\n",
    "Gain_Energy = 1e5\n",
    "TimeStep = 1\n",
    "FilteredOutput_vqvp = np.zeros((TotalTimeSteps,NumberOfNodes))\n",
    "IntermediateOutput_vqvp= np.zeros((TotalTimeSteps,NumberOfNodes))\n",
    "Epsilon_vqvp = np.zeros((TotalTimeSteps,NumberOfNodes))\n",
    "\n",
    "#ZIP load modeling\n",
    "ConstantImpedanceFraction = 0.2\n",
    "ConstantCurrentFraction = 0.05\n",
    "ConstantPowerFraction = 0.75\n",
    "ZIP_demand = np.zeros((TotalTimeSteps,IeeeFeeder,3), dtype=np.complex)\n",
    "\n",
    "for node in range(1,IeeeFeeder):\n",
    "    ZIP_demand[:,node,:] = np.array([ConstantPowerFraction*Load[:,node].astype(complex), \n",
    "                            ConstantCurrentFraction*Load[:,node].astype(complex), \n",
    "                            ConstantImpedanceFraction*Load[:,node].astype(complex)]).T*(1 + 1j*tan(acos(power_factor)))\n",
    "    \n",
    "#Power Flow with QVQP Control Case\n",
    "Sbar =  MaxGenerationPossible * GenerationScalingFactor\n",
    "V_vqvp = np.zeros((IeeeFeeder,TotalTimeSteps), dtype=np.complex)\n",
    "S_vqvp = np.zeros((IeeeFeeder,TotalTimeSteps), dtype=np.complex)\n",
    "IterationCounter_vqvp = np.zeros((IeeeFeeder,TotalTimeSteps))\n",
    "PowerEachTimeStep_vqvp = np.zeros((IeeeFeeder,3), dtype=np.complex)\n",
    "SolarGeneration_vqvp = Generation * GenerationScalingFactor\n",
    "InverterReactivePower = np.zeros(Generation.shape)\n",
    "InverterRealPower = np.zeros(Generation.shape)\n",
    "InverterRateOfChangeLimit = 100 \n",
    "InverterRateOfChangeActivate = 0\n",
    "\n",
    "#Drop Control Parameters\n",
    "VQ_start = 1.01\n",
    "VQ_end = 1.015\n",
    "VP_start = 1.015\n",
    "VP_end = 1.02\n",
    "#VBP is this the config of the control at each time step?\n",
    "VBP = np.full([IeeeFeeder, 4, TotalTimeSteps], np.nan)\n",
    "VBP[:,0,0] = VQ_start\n",
    "VBP[:,1,0] = VQ_end\n",
    "VBP[:,2,0] = VP_start\n",
    "VBP[:,3,0] = VP_end\n",
    "FilteredVoltage = np.zeros(Generation.shape)\n",
    "FilteredVoltageCalc = np.zeros(Generation.shape)\n",
    "InverterLPF = 1\n",
    "ThreshHold_vqvp = 0.25\n",
    "V0 = np.full((TotalTimeSteps, 1), SlackBusVoltage)\n",
    "#Adaptive controller parameters\n",
    "upk = np.zeros(IntermediateOutput_vqvp.shape)\n",
    "uqk = upk\n",
    "kq = 100\n",
    "kp = 100\n",
    "\n",
    "#Delays                 [  1   2   3*  4   5   6*  7*  8*  9* 10* 11* 12* 13*\n",
    "Delay_VoltageSampling = [0, 0,  1, 0, 0,  1,  1,  1,  1,  1,  1,  1,  1]\n",
    "Delay_VBPCurveShift =   [0 ,0 ,2 ,0 ,0 ,2 ,2 ,2 ,2 ,2 ,2 ,2 ,2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VBP = np.full([IeeeFeeder, 4, TotalTimeSteps], np.nan)\n",
    "for i in range(1441):\n",
    "    VBP[:,0,i] = VQ_start\n",
    "    VBP[:,1,i] = VQ_end\n",
    "    VBP[:,2,i] = VP_start\n",
    "    VBP[:,3,i] = VP_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voltage_observer(vk, vkm1, psikm1, epsilonkm1, ykm1, f_hp, f_lp, gain, T):\n",
    "    Vmagk = abs(vk)\n",
    "    Vmagkm1 = abs(vkm1)\n",
    "    psik = (Vmagk - Vmagkm1 - (f_hp*T/2-1)*psikm1)/(1+f_hp*T/2)\n",
    "    epsilonk = gain*(psik**2)\n",
    "    yk = (T*f_lp*(epsilonk + epsilonkm1) - (T*f_lp - 2)*ykm1)/(2 + T*f_lp)\n",
    "    return yk, psik, epsilonk\n",
    "\n",
    "def inverter_VoltVarVoltWatt_model(gammakm1,solar_irr,Vk,Vkm1,VBP,T,lpf,Sbar,pkm1,qkm1,ROC_lim,InverterRateOfChangeActivate,ksim,Delay_VoltageSampling):\n",
    "    Vmagk = abs(Vk)\n",
    "    Vmagkm1 = abs(Vkm1) \n",
    "    gammakcalc = (T*lpf*(Vmagk + Vmagkm1) - (T*lpf - 2)*gammakm1)/(2 + T*lpf)\n",
    "    if ksim % Delay_VoltageSampling == 0:\n",
    "        gammakused = gammakcalc\n",
    "    else: \n",
    "        gammakused = gammakm1\n",
    "    \n",
    "    pk = 0\n",
    "    qk = 0\n",
    "    c = 0\n",
    "    q_avail = 0\n",
    "\n",
    "    if solar_irr < 2500:\n",
    "        pk = 0\n",
    "        qk = 0\n",
    "    elif solar_irr >= 2500:\n",
    "        if gammakused <= VBP[2]:\n",
    "            pk = -solar_irr\n",
    "            q_avail = (Sbar**2 - pk**2)**(1/2)\n",
    "            if gammakused <= VBP[0]:\n",
    "                qk = 0\n",
    "            elif gammakused > VBP[0] and gammakused <= VBP[0]:\n",
    "                c = q_avail/(VBP[1] - VBP[0])\n",
    "                qk = c*(gammakused - VBP[0])\n",
    "            else:\n",
    "                qk = q_avail       \n",
    "        elif gammakused > VBP[2] and gammakused < VBP[3]:\n",
    "            d = -solar_irr/(VBP[3] - VBP[2])\n",
    "            pk = -(d*(gammakused - VBP[2]) + solar_irr);\n",
    "            qk = (Sbar**2 - pk**2)**(1/2);      \n",
    "        elif gammakused >= VBP[3]:\n",
    "            qk = Sbar\n",
    "            pk = 0\n",
    "    return qk,pk,gammakused, gammakcalc, c, q_avail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize PowerEachTimeStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the agent!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _state(object):\n",
    "    def __init__(self, PET, V, S, InvReal, InvReact, FV, FVC, Fo, Io, Ep):\n",
    "        self.PET = PET\n",
    "        self.V = V\n",
    "        self.S = S\n",
    "        self.InvReal = InvReal\n",
    "        self.InvReact = InvReact\n",
    "        self.FV = FV\n",
    "        self.FVC = FVC\n",
    "        self.Fo = Fo\n",
    "        self.Io = Io\n",
    "        self.Ep = Ep\n",
    "    \n",
    "    def get_state_agent(self, agent):\n",
    "        arg = (self.PET[agent], np.array([self.V[agent]]), np.array([self.S[agent]]), np.array([self.InvReal[agent]]), np.array([self.InvReact[agent]]),np.array([self.FV[agent]]),np.array([self.FVC[agent]]))\n",
    "        return abs(np.concatenate(arg, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class env(object):\n",
    "    \n",
    "    ######### reset the env ####################\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        # a state of env contain: state it is in, terminal or not, in which step it is in\n",
    "        self.stage = 0\n",
    "        PET, V, S = self._init_PET_VS()\n",
    "        InvReal = np.zeros(NumberOfNodes)\n",
    "        InvReact = np.zeros(NumberOfNodes)\n",
    "        FV = np.zeros(NumberOfNodes)\n",
    "        FVC = np.zeros(NumberOfNodes)\n",
    "        Fo = np.zeros(NumberOfNodes)\n",
    "        Io = np.zeros(NumberOfNodes)\n",
    "        Ep = np.zeros(NumberOfNodes)\n",
    "        self.state = _state(PET, V, S, InvReal, InvReact, FV, FVC, Fo, Io, Ep)\n",
    "        self.terminal = False\n",
    "        return self.state.get_state_agent(agent)\n",
    "    #############################################\n",
    "    # next state, execute an action #############\n",
    "    #############################################\n",
    "    def step(self, action):\n",
    "        #return next state, reward, terminal or not, precise info\n",
    "        nextPET = self._cal_next_PET()\n",
    "        nextV, nextS = self._cal_next_VS(nextPET)\n",
    "        nextInvReal, nextInvReact, nextFV, nextFVC = self._cal_next_Inv(nextV, action)\n",
    "        nextFo, nextIo, nextEp = self._cal_next_FIE(nextV)\n",
    "        nextState = _state(nextPET, nextV, nextS, nextInvReal, nextInvReact, nextFV, nextFVC, nextFo, nextIo, nextEp) \n",
    "        \n",
    "        #update new state, reward and stage\n",
    "        self.state = nextState\n",
    "        self.reward = -nextFo\n",
    "        self.stage += 1\n",
    "        \n",
    "        #check if terminal\n",
    "        if (self.stage == TotalTimeSteps-1):\n",
    "            self.terminal = True\n",
    "        \n",
    "        return self.state.get_state_agent(agent), self.reward, self.terminal\n",
    "   ################################################     \n",
    "    def _init_PET_VS(self):\n",
    "        for knode in LoadList:\n",
    "            PowerEachTimeStep_vqvp[knode,:] = np.array([ZIP_demand[0,knode,0] - SolarGeneration_vqvp[0,knode],\n",
    "                                                        ZIP_demand[0,knode,1],\n",
    "                                                        ZIP_demand[0,knode,2]])\n",
    "        V, S = FBSfun(matlab_engine, V0[0,0], PowerEachTimeStep_vqvp, Z, FeederMap)\n",
    "        return PowerEachTimeStep_vqvp, V, S       \n",
    "    \n",
    "    def _cal_next_PET(self):\n",
    "        ksim = self.stage\n",
    "        currentState = self.state\n",
    "        for knode in LoadList:\n",
    "            PowerEachTimeStep_vqvp[knode,:] = np.array([ZIP_demand[ksim+1,knode,0] + currentState.InvReal[knode]\n",
    "                                                         + 1j*currentState.InvReact[knode], \n",
    "                                                        ZIP_demand[ksim+1,knode,1], \n",
    "                                                        ZIP_demand[ksim+1,knode,2]])\n",
    "        return PowerEachTimeStep_vqvp\n",
    "    \n",
    "    def _cal_next_VS(self, nextPET):\n",
    "        ksim = self.stage\n",
    "        V, S = FBSfun(matlab_engine,V0[ksim+1,0], nextPET, Z,FeederMap)\n",
    "        return V, S  \n",
    "    \n",
    "    def _cal_next_Inv(self, nextV, action):\n",
    "        ksim = self.stage\n",
    "        currentState = self.state\n",
    "        \n",
    "        InvReal = np.zeros(NumberOfNodes)\n",
    "        InvReact = np.zeros(NumberOfNodes)\n",
    "        FV = np.zeros(NumberOfNodes)\n",
    "        FVC = np.zeros(NumberOfNodes)\n",
    "        \n",
    "        for knode in LoadList:\n",
    "            InvReact[knode], InvReal[knode], FV[knode], FVC[knode], _, _ = inverter_VoltVarVoltWatt_model(\n",
    "                     currentState.FV[knode], SolarGeneration_vqvp[ksim+1,knode], \n",
    "                     abs(nextV[knode]), abs(currentState.V[knode]), \n",
    "                     action[knode], TimeStep, InverterLPF, \n",
    "                     Sbar[knode], currentState.InvReal[knode], \n",
    "                     currentState.InvReact[knode], InverterRateOfChangeLimit, \n",
    "                     InverterRateOfChangeActivate, ksim+1, Delay_VoltageSampling[knode])\n",
    "        return InvReal, InvReact, FV, FVC\n",
    "    \n",
    "    # ok\n",
    "    def _cal_next_FIE(self, nextV):\n",
    "        currentState = self.state\n",
    "        Fo = np.zeros(NumberOfNodes)\n",
    "        Io = np.zeros(NumberOfNodes)\n",
    "        Ep = np.zeros(NumberOfNodes)\n",
    "        for knode in LoadList:\n",
    "            Fo[knode], Io[knode], Ep[knode] = voltage_observer(nextV[knode], currentState.V[knode], \n",
    "                                                              currentState.Io[knode], currentState.Ep[knode],\n",
    "                                                              currentState.Fo[knode], HighPassFilterFrequency,\n",
    "                                                              LowPassFilterFrequency, Gain_Energy, TimeStep) \n",
    "        return Fo, Io, Ep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a buffer for training data\n",
    "\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "\n",
    "    def __init__(self, buffer_size):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.count = 0\n",
    "        self.buffer = deque()\n",
    "\n",
    "    def add(self, s, a, r, t, s2):\n",
    "        experience = (s, a, r, t, s2)\n",
    "        if self.count < self.buffer_size: \n",
    "            self.buffer.append(experience)\n",
    "            self.count += 1\n",
    "        else:\n",
    "            self.buffer.popleft()\n",
    "            self.buffer.append(experience)\n",
    "\n",
    "    def size(self):\n",
    "        return self.count\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        '''     \n",
    "        batch_size specifies the number of experiences to add \n",
    "        to the batch. If the replay buffer has less than batch_size\n",
    "        elements, simply return all of the elements within the buffer.\n",
    "        Generally, you'll want to wait until the buffer has at least \n",
    "        batch_size elements before beginning to sample from it.\n",
    "        '''\n",
    "        batch = []\n",
    "\n",
    "        if self.count < batch_size:\n",
    "            batch = random.sample(self.buffer, self.count)\n",
    "        else:\n",
    "            batch = random.sample(self.buffer, batch_size)\n",
    "\n",
    "        s_batch = np.array([_[0] for _ in batch])\n",
    "        a_batch = np.array([_[1] for _ in batch])\n",
    "        r_batch = np.array([_[2] for _ in batch])\n",
    "        t_batch = np.array([_[3] for _ in batch])\n",
    "        s2_batch = np.array([_[4] for _ in batch])\n",
    "\n",
    "        return s_batch, a_batch, r_batch, t_batch, s2_batch\n",
    "\n",
    "    def clear(self):\n",
    "        self.buffer.clear()\n",
    "        self.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing action noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrnsteinUhlenbeckActionNoise:\n",
    "    def __init__(self, mu, sigma=0.3, theta=.15, dt=1e-2, x0=None):\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "                self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(self.mu, self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define actor\n",
    "class ActorNetwork(object):\n",
    "    def __init__(self, sess, state_dim, action_dim, action_bound, learning_rate, tau, batch_size):\n",
    "        self.sess = sess\n",
    "        self.s_dim = state_dim\n",
    "        self.a_dim = action_dim\n",
    "        self.action_bound = action_bound\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tau = tau\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        #actor network\n",
    "        self.inputs, self.out, self.scaled_out = self.create_actor_network()\n",
    "        self.network_params = tf.trainable_variables()\n",
    "        #create an copy of actor network as target\n",
    "        self.target_inputs, self.target_out, self.target_scaled_out = self.create_actor_network()\n",
    "        self.target_network_params = tf.trainable_variables()[len(self.network_params):]\n",
    "        \n",
    "        #periodically update target network\n",
    "        self.update_target_network_params = \\\n",
    "            [self.target_network_params[i].assign(tf.multiply(self.network_params[i], self.tau)+\n",
    "                                                tf.multiply(self.target_network_params[i], 1. -self.tau))\n",
    "                                            for i in range(len(self.target_network_params))]\n",
    "        \n",
    "        #still not understand\n",
    "        self.action_gradient = tf.placeholder(tf.float32, [None, self.a_dim])\n",
    "        self.unnormalized_actor_gradients = tf.gradients(self.scaled_out,self.network_params,-self.action_gradient)\n",
    "        self.actor_gradients = list(map(lambda x:tf.div(x, self.batch_size), self.unnormalized_actor_gradients))\n",
    " \n",
    "        self.optimize = tf.train.AdamOptimizer(self.learning_rate).apply_gradients(zip(self.actor_gradients, self.network_params))\n",
    "        self.num_trainable_vars = len(self.network_params) + len(self.target_network_params)\n",
    "        print(\"Created Actor Network!\")\n",
    "        \n",
    "    def create_actor_network(self):\n",
    "        inputs = tflearn.input_data(shape=[None, self.s_dim])\n",
    "        net = tflearn.fully_connected(inputs, 400)\n",
    "        net = tflearn.layers.normalization.batch_normalization(net)\n",
    "        net = tflearn.activations.relu(net)\n",
    "        net = tflearn.fully_connected(net, 300)\n",
    "        net = tflearn.layers.normalization.batch_normalization(net)\n",
    "        net = tflearn.activations.relu(net)\n",
    "        #final layer\n",
    "        w_init = tflearn.initializations.uniform(minval=-0.003, maxval = 0.003)\n",
    "        out = tflearn.fully_connected(net, self.a_dim, activation='tanh', weights_init = w_init)\n",
    "        scaled_out = tf.multiply(out, self.action_bound) #action in range (-0.5 to 0.5 -> need to transfer 0.5 and 1)\n",
    "        return inputs, out, scaled_out\n",
    "    \n",
    "    def train(self, inputs, a_gradient):\n",
    "        self.sess.run(self.optimize, feed_dict={\n",
    "            self.inputs: inputs,\n",
    "            self.action_gradient: a_gradient\n",
    "        })\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        return self.sess.run(self.scaled_out, feed_dict={\n",
    "            self.inputs: inputs\n",
    "        })\n",
    "    \n",
    "    def predict_target(self, inputs):\n",
    "        return self.sess.run(self.scaled_out, feed_dict={\n",
    "            self.inputs: inputs\n",
    "        })\n",
    "    \n",
    "    def update_target_network(self):\n",
    "        self.sess.run(self.update_target_network_params)\n",
    "    \n",
    "    def get_num_trainable_vars(self):\n",
    "        return self.num_trainable_vars\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define critic\n",
    "class CriticNetwork(object):\n",
    "    def __init__(self, sess, state_dim, action_dim, learning_rate, tau, gamma, num_actor_vars):\n",
    "        self.sess = sess\n",
    "        self.s_dim = state_dim\n",
    "        self.a_dim = action_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tau = tau\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.inputs, self.action, self.out = self.create_critic_network()\n",
    "        self.network_params = tf.trainable_variables()[num_actor_vars:]\n",
    "        \n",
    "        self.target_inputs, self.target_action, self.target_out = self.create_critic_network()\n",
    "        self.target_network_params = tf.trainable_variables()[(len(self.network_params)+num_actor_vars):]\n",
    "        \n",
    "        self.update_target_network_params = [self.target_network_params[i].assign(tf.multiply(self.network_params[i], self.tau)\n",
    "                                                                                  + tf.multiply(self.target_network_params[i], 1. - self.tau))\n",
    "                                             for i in range(len(self.target_network_params))]\n",
    "        \n",
    "        self.predicted_q_value = tf.placeholder(tf.float32, [None, 1])\n",
    "        self.loss = tflearn.mean_square(self.predicted_q_value, self.out)\n",
    "        \n",
    "        self.optimize = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "        \n",
    "        self.action_grads = tf.gradients(self.out, self.action)\n",
    "        print(\"Created Critic Network!\")\n",
    "    def create_critic_network(self):\n",
    "        inputs = tflearn.input_data(shape=[None, self.s_dim])\n",
    "        action = tflearn.input_data(shape=[None, self.a_dim])\n",
    "        net = tflearn.fully_connected(inputs, 400)\n",
    "        net = tflearn.layers.normalization.batch_normalization(net)\n",
    "        net = tflearn.activations.relu(net)\n",
    "        \n",
    "        t1 = tflearn.fully_connected(net, 300)\n",
    "        t2 = tflearn.fully_connected(action, 300)\n",
    "        net = tflearn.activation(tf.matmul(net, t1.W) + tf.matmul(action, t2.W) + t2.b, activation = 'relu')\n",
    "        \n",
    "        w_init = tflearn.initializations.uniform(minval=-0.003, maxval=0.003)\n",
    "        out = tflearn.fully_connected(net, 1, weights_init=w_init)\n",
    "        return inputs, action, out\n",
    "    \n",
    "    def train(self, inputs, action, predicted_q_value):\n",
    "        return self.sess.run([self.out, self.optimize], feed_dict = {\n",
    "            self.inputs: inputs,\n",
    "            self.inputs: action,\n",
    "            self.predicted_q_value: predicted_q_value\n",
    "        })\n",
    "    \n",
    "    def predict(self, inputs, action):\n",
    "        return self.sess.run(self.out, feed_dict={\n",
    "            self.inputs: inputs,\n",
    "            self.action: action\n",
    "        })\n",
    "    \n",
    "    def predict_target(self, inputs, action):\n",
    "        return self.sess.run(self.target_out, feed_dict={\n",
    "            self.target_inputs: inputs,\n",
    "            self.target_action: action\n",
    "        })\n",
    "    \n",
    "    def action_gradients(self, inputs, action):\n",
    "        return self.sess.run(self.action_grads, feed_dict={\n",
    "            self.inputs: inputs,\n",
    "            self.action: action\n",
    "        })\n",
    "    \n",
    "    def update_target_network(self):\n",
    "        self.sess.run(self.update_target_network_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_summaries():\n",
    "    episode_reward = tf.Variable(0.)\n",
    "    tf.summary.scalar(\"Reward\", episode_reward)\n",
    "    episode_ave_max_q = tf.Variable(0.)\n",
    "    tf.summary.scalar(\"Qmax value\", episode_ave_max_q)\n",
    "    \n",
    "    summary_vars = [episode_reward, episode_ave_max_q]\n",
    "    summary_ops = tf.summary.merge_all()\n",
    "    \n",
    "    return summary_ops, summary_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sess, env, args, actor, critic, actor_noise):\n",
    "    summary_ops, summary_vars = build_summaries()\n",
    "    sess.run(tf.global_variable_initilizer())\n",
    "    writer = tf.summary.FileWriter(args['summary_dir'], sess.graph)\n",
    "    actor.update_target_network()\n",
    "    critic.update_target_network()\n",
    "    replay_buffer = ReplayBuffer(int(args['buffer_size']), int(args['random_seed']))\n",
    "    \n",
    "    for i in range(int(args['max_episodes'])):\n",
    "        s = env.reset()\n",
    "        ep_reward = 0\n",
    "        ep_ave_max_q = 0\n",
    "        \n",
    "        for j in range(int(args['max_episode_len'])):\n",
    "            a = actor.predict(np.reshape(s, (1, actor.s_dim))) + actor_noise()\n",
    "            \n",
    "            translate = np.array([0.5, 0.5, 1, 1])\n",
    "            allAction[agent] = a + translate\n",
    "            s2, r, terminal = env.step(allAction)\n",
    "            \n",
    "            replay_buffer.add(np.reshape(s, (actor.s_dim,)), np.reshape(a, (actor.a_dim,)), r,\n",
    "                              terminal, np.reshape(s2, (actor.s_dim,)))\n",
    "\n",
    "            # Keep adding experience to the memory until\n",
    "            # there are at least minibatch size samples\n",
    "            if replay_buffer.size() > int(args['minibatch_size']):\n",
    "                s_batch, a_batch, r_batch, t_batch, s2_batch = \\\n",
    "                    replay_buffer.sample_batch(int(args['minibatch_size']))\n",
    "\n",
    "                # Calculate targets\n",
    "                target_q = critic.predict_target(\n",
    "                    s2_batch, actor.predict_target(s2_batch))\n",
    "\n",
    "                y_i = []\n",
    "                for k in range(int(args['minibatch_size'])):\n",
    "                    if t_batch[k]:\n",
    "                        y_i.append(r_batch[k])\n",
    "                    else:\n",
    "                        y_i.append(r_batch[k] + critic.gamma * target_q[k])\n",
    "\n",
    "                # Update the critic given the targets\n",
    "                predicted_q_value, _ = critic.train(\n",
    "                    s_batch, a_batch, np.reshape(y_i, (int(args['minibatch_size']), 1)))\n",
    "\n",
    "                ep_ave_max_q += np.amax(predicted_q_value)\n",
    "\n",
    "                # Update the actor policy using the sampled gradient\n",
    "                a_outs = actor.predict(s_batch)\n",
    "                grads = critic.action_gradients(s_batch, a_outs)\n",
    "                actor.train(s_batch, grads[0])\n",
    "\n",
    "                # Update target networks\n",
    "                actor.update_target_network()\n",
    "                critic.update_target_network()\n",
    "\n",
    "            s = s2\n",
    "            ep_reward += r\n",
    "\n",
    "            if terminal:\n",
    "\n",
    "                summary_str = sess.run(summary_ops, feed_dict={\n",
    "                    summary_vars[0]: ep_reward,\n",
    "                    summary_vars[1]: ep_ave_max_q / float(j)\n",
    "                })\n",
    "\n",
    "                writer.add_summary(summary_str, i)\n",
    "                writer.flush()\n",
    "\n",
    "                print('| Reward: {:d} | Episode: {:d} | Qmax: {:.4f}'.format(int(ep_reward), \\\n",
    "                        i, (ep_ave_max_q / float(j))))\n",
    "                break\n",
    "                \n",
    "#main body\n",
    "\n",
    "def main(args):\n",
    "    with tf.Session() as sess:\n",
    "        silmulation = env()\n",
    "        tf.set_random_seed(int(args['random_seed']))\n",
    "\n",
    "        state_dim = 10\n",
    "        action_dim = 4\n",
    "        action_bound = 0.5\n",
    "        # Ensure action bound is symmetric\n",
    "        print(\"creating actor!\")\n",
    "        actor = ActorNetwork(sess, state_dim, action_dim, action_bound,\n",
    "                             float(args['actor_lr']), float(args['tau']),\n",
    "                             int(args['minibatch_size']))\n",
    "\n",
    "        critic = CriticNetwork(sess, state_dim, action_dim,\n",
    "                               float(args['critic_lr']), float(args['tau']),\n",
    "                               float(args['gamma']),\n",
    "                               actor.get_num_trainable_vars())\n",
    "        \n",
    "        actor_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(action_dim))\n",
    "\n",
    "        train(sess, simulation, args, actor, critic, actor_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating actor!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 10 and 300 for 'add_456' (op: 'Add') with input shapes: [10,400], [300,4].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1566\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1567\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 10 and 300 for 'add_456' (op: 'Add') with input shapes: [10,400], [300,4].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-68fa6ed17209>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mallAction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVBP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#need to run simulation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-66-3c36b8647216>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     83\u001b[0m         actor = ActorNetwork(sess, state_dim, action_dim, action_bound,\n\u001b[0;32m     84\u001b[0m                              \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'actor_lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tau'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                              int(args['minibatch_size']))\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         critic = CriticNetwork(sess, state_dim, action_dim,\n",
      "\u001b[1;32m<ipython-input-70-080b269b0ce2>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess, state_dim, action_dim, action_bound, learning_rate, tau, batch_size)\u001b[0m\n\u001b[0;32m     20\u001b[0m         self.update_target_network_params =             [self.target_network_params[i].assign(tf.multiply(self.network_params[i], self.tau)+\n\u001b[0;32m     21\u001b[0m                                                 tf.multiply(self.target_network_params[i], 1. -self.tau))\n\u001b[1;32m---> 22\u001b[1;33m                                             for i in range(len(self.target_network_params))]\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#still not understand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-080b269b0ce2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     20\u001b[0m         self.update_target_network_params =             [self.target_network_params[i].assign(tf.multiply(self.network_params[i], self.tau)+\n\u001b[0;32m     21\u001b[0m                                                 tf.multiply(self.target_network_params[i], 1. -self.tau))\n\u001b[1;32m---> 22\u001b[1;33m                                             for i in range(len(self.target_network_params))]\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#still not understand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    977\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m--> 306\u001b[1;33m         \"Add\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m    307\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3392\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3394\u001b[0m       \u001b[1;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1734\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1735\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 10 and 300 for 'add_456' (op: 'Add') with input shapes: [10,400], [300,4]."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tflearn\n",
    "\n",
    "import os\n",
    "\n",
    "args = {}\n",
    "args['actor_lr'] = 0.0001\n",
    "args['critic_lr'] = 0.001\n",
    "args['gamma'] = 0.99\n",
    "args['tau'] = 0.001\n",
    "args['buffer_size'] = 10000\n",
    "args['minibatch_size'] = 64\n",
    "args['random_seed'] = 1234\n",
    "args['max-episodes'] = 50000\n",
    "args['max-episode-len'] = TotalTimeSteps\n",
    "args['summary_dir'] = os.getcwd()\n",
    "args['random_seed'] = 1234\n",
    "#in this chapter, we only want to control 1 agent, other agents have a constant VBP\n",
    "#agent \n",
    "agent = 2\n",
    "#init action \n",
    "allAction = VBP[:,:,0] #need to run simulation\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'V'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-d61a9f7e119c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTotalTimeSteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSilmulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mVoltage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'V'"
     ]
    }
   ],
   "source": [
    "action = VBP[:,:,0]\n",
    "Silmulation = env()\n",
    "Silmulation.reset()\n",
    "Voltage = [Silmulation.state.V]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import tflearn\n",
    "import argparse\n",
    "import pprint as pp\n",
    "\n",
    "env = gym.make('Pendulum-v0')\n",
    "s =env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ksim in range(TotalTimeSteps):\n",
    "    ############################################################\n",
    "    ###############calculate new simulation#####################\n",
    "    ############################################################\n",
    "    #CALCULATE NET ZIP LOADS\n",
    "    for node_iter in range(NumberOfLoads):\n",
    "        knode = LoadList[node_iter]\n",
    "        if ksim == 0:\n",
    "            PowerEachTimeStep_vqvp[knode,:] = np.array([ZIP_demand[ksim,knode,0] - SolarGeneration_vqvp[ksim,knode],\n",
    "                                                        ZIP_demand[ksim,knode,1],\n",
    "                                                        ZIP_demand[ksim,knode,2]])\n",
    "        else:\n",
    "            PowerEachTimeStep_vqvp[knode,:] = np.array([ZIP_demand[ksim,knode,0] + InverterRealPower[ksim-1,knode]\n",
    "                                                         + 1j*InverterReactivePower[ksim-1,knode], \n",
    "                                                        ZIP_demand[ksim,knode,1], \n",
    "                                                        ZIP_demand[ksim,knode,2]])\n",
    "    #RUN FORWARD-BACKWARD SWEEP\n",
    "    V_vqvp[:,ksim],S_vqvp[:,ksim] = FBSfun(matlab_engine,V0[ksim,0],PowerEachTimeStep_vqvp,Z,FeederMap)\n",
    "    \n",
    "    #RUN INVERTER FUNCTION TO OUTPUT P/Q\n",
    "    if (0 < ksim < TotalTimeSteps-1):\n",
    "        for node_iter in range(NumberOfLoads):\n",
    "            knode = LoadList[node_iter]\n",
    "            InverterReactivePower[ksim,knode],InverterRealPower[ksim,knode],FilteredVoltage[ksim,knode],FilteredVoltageCalc[ksim,knode],_, _ = inverter_VoltVarVoltWatt_model(\n",
    "                FilteredVoltage[ksim-1,knode], SolarGeneration_vqvp[ksim,knode], \n",
    "                abs(V_vqvp[knode,ksim]), abs(V_vqvp[knode,ksim-1]), \n",
    "                VBP[knode,:,ksim], TimeStep, InverterLPF, \n",
    "                Sbar[knode], InverterRealPower[ksim-1,knode], \n",
    "                InverterReactivePower[ksim-1,knode], InverterRateOfChangeLimit, \n",
    "                InverterRateOfChangeActivate, ksim, Delay_VoltageSampling[knode])\n",
    "    \n",
    "    #RUN OBSERVER FUNCTION\n",
    "    for node_iter in range(NumberOfLoads):\n",
    "        knode = LoadList[node_iter]\n",
    "        if (ksim > 0):\n",
    "            FilteredOutput_vqvp[ksim,knode],IntermediateOutput_vqvp[ksim,knode],Epsilon_vqvp[ksim,knode] = voltage_observer(V_vqvp[knode,ksim], V_vqvp[knode,ksim-1], \n",
    "                                                        IntermediateOutput_vqvp[ksim-1,knode], Epsilon_vqvp[ksim-1,knode], \n",
    "                                                        FilteredOutput_vqvp[ksim-1,knode], HighPassFilterFrequency, \n",
    "                                                        LowPassFilterFrequency, Gain_Energy, TimeStep)        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
