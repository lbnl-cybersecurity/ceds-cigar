{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model Converged. Proceeding to Next Step.\n",
      "OpenDSS Model Compliation Done.\n",
      "Reading Data for Pecan Street is done.\n",
      "Starting Interpolation...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from DSSStartup import DSSStartup\n",
    "from setInfo import *\n",
    "from getInfo import *\n",
    "import matplotlib.pyplot as plt\n",
    "from math import tan,acos\n",
    "import copy\n",
    "import pandas as pd\n",
    "import time\n",
    "from replay_buffer import ReplayBuffer\n",
    "import numpy as np\n",
    "#######################################################\n",
    "#######################################################\n",
    "###Global variable initialization and error checking###\n",
    "#######################################################\n",
    "#######################################################\n",
    "Sbase=1\n",
    "LoadScalingFactor = 1.5\n",
    "GenerationScalingFactor = 5 \n",
    "SlackBusVoltage = 1.04 \n",
    "NoiseMultiplyer= 0\n",
    "\n",
    "#Set simulation analysis period - the simulation is from StartTime to EndTime\n",
    "StartTime = 42900\n",
    "EndTime = 44000\n",
    "EndTime += 1 # creating a list, last element does not count, so we increase EndTime by 1\n",
    "#Set hack parameters\n",
    "TimeStepOfHack = 300\n",
    "PercentHacked = np.array([0,0,0,0,0, 0,0,.5,0,0,.5,.5,.5,.5,.5,0,0,.5, 0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "#PercentHacked = np.array([0,0,0,0,0, .1,.1,.1,.1,.1,.1,.1,.1,.1,.1,.1,.1,.1, 0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "#Set initial VBP parameters for uncompromised inverters\n",
    "VQ_start = 1.01\n",
    "VQ_end = 1.03\n",
    "VP_start = 1.03\n",
    "VP_end = 1.05\n",
    "\n",
    "#Set delays for each node\n",
    "\n",
    "Delay_VoltageSampling = np.array([0,0,0,0,0, 10,10,10,10,10,10,10,10,10,10,10,10,10, 0,0,0,0,0,0,0,0,0,0,0,0,0]) \n",
    "Delay_VBPCurveShift =   np.array([0,0,0,0,0, 60,60,60,60,60,60,60,60,60,60,60,60,60, 0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "#Set observer voltage threshold\n",
    "ThreshHold_vqvp = 0.25\n",
    "power_factor=0.9\n",
    "pf_converted=tan(acos(power_factor))\n",
    "Number_of_Inverters = 13 #even feeder is 34Bus, we only have 13 inverters\n",
    "\n",
    "\n",
    "#Error checking of the global variable -- TODO: add error handling here!\n",
    "if EndTime < StartTime or EndTime < 0 or StartTime < 0:\n",
    "    print('Setup Simulation Times Appropriately.')\n",
    "if NoiseMultiplyer < 0:\n",
    "    print('Setup Noise Multiplyer Correctly.')\n",
    "    \n",
    "DSSStart = DSSStartup()\n",
    "DSSText =DSSStart['dsstext']\n",
    "DSSSolution = DSSStart['dsssolution']\n",
    "DSSCircuit = DSSStart['dsscircuit']\n",
    "DSSObj = DSSStart['dssobj']\n",
    "DSSMon = DSSCircuit.Monitors\n",
    "DSSText.command = 'Compile C:\\\\feeders\\\\feeder34_B_NR\\\\feeder34_B_NR.dss'\n",
    "DSSSolution.Solve()\n",
    "if not DSSSolution.Converged:\n",
    "    print('Initial Solution Not Converged. Check Model for Convergence')\n",
    "else:\n",
    "    print('Initial Model Converged. Proceeding to Next Step.')\n",
    "    #Doing this solve command is required for GridPV, that is why the monitors\n",
    "    #go under a reset process\n",
    "    DSSMon.ResetAll\n",
    "    setSolutionParams(DSSObj,'daily',1,1,'off',1000000,30000)\n",
    "    #Easy process to get all names and count of loads, a trick to avoid\n",
    "    #some more lines of code\n",
    "    TotalLoads=DSSCircuit.Loads.Count\n",
    "    AllLoadNames=DSSCircuit.Loads.AllNames\n",
    "    print('OpenDSS Model Compliation Done.')\n",
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "####         Load data from file                    ###\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "#Retrieving the data from the load profile\n",
    "TimeResolutionOfData=10 #resolution in minute\n",
    "#Get the data from the Testpvnum folder\n",
    "#Provide Your Directory - move testpvnum10 from github to drive C: \n",
    "FileDirectoryBase ='C:\\\\feeders\\\\testpvnum10\\\\';\n",
    "QSTS_Time = list(range(1441)) #This can be changed based on the available data - for example, 1440 timesteps\n",
    "QSTS_Data = np.zeros((len(QSTS_Time) ,4,TotalLoads)) #4 columns as there are four columns of data available in the .mat file\n",
    "\n",
    "for node in range(TotalLoads):\n",
    "    #This is created manually according to the naming of the folder\n",
    "    FileDirectoryExtension = 'node_' + str(node+1) + '_pv_' +str(TimeResolutionOfData) + '_minute.csv'\n",
    "    #The total file directory\n",
    "    FileName = FileDirectoryBase + FileDirectoryExtension\n",
    "    #Load the file\n",
    "    MatFile = np.genfromtxt(FileName, delimiter=',')    \n",
    "    QSTS_Data[:,:,node] = MatFile #Putting the loads to appropriate nodes according to the loadlist\n",
    "    \n",
    "Generation = QSTS_Data[:,1,:]*GenerationScalingFactor #solar generation\n",
    "Load = QSTS_Data[:,3,:]*LoadScalingFactor #load demand\n",
    "Generation = np.squeeze(Generation)/Sbase  #To convert to per unit, it should not be multiplied by 100\n",
    "Load = np.squeeze(Load)/Sbase\n",
    "print('Reading Data for Pecan Street is done.')\n",
    "\n",
    "############################################################\n",
    "############################################################\n",
    "#### Interpolate to change data from minutes to seconds ####\n",
    "############################################################\n",
    "############################################################\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "print('Starting Interpolation...')\n",
    "\n",
    "#interpolation for the whole period...\n",
    "Time = list(range(StartTime,EndTime))\n",
    "TotalTimeSteps = len(Time)\n",
    "LoadSeconds = np.empty([3600*24, TotalLoads])\n",
    "GenerationSeconds = np.empty([3600*24, TotalLoads])\n",
    "# Interpolate to get minutes to seconds\n",
    "for node in range(TotalLoads): # i is node\n",
    "    t_seconds = np.linspace(1,len(Load[:,node]), int(3600*24/1))\n",
    "    f = interp1d(range(len(Load[:,node])), Load[:,node], kind='cubic', fill_value=\"extrapolate\")\n",
    "    LoadSeconds[:,node] = f(t_seconds) #spline method in matlab equal to Cubic Spline -> cubic\n",
    "    \n",
    "    f = interp1d(range(len(Generation[:,node])), Generation[:,node], kind='cubic', fill_value=\"extrapolate\")\n",
    "    GenerationSeconds[:,node]= f(t_seconds)\n",
    "\n",
    "# Initialization\n",
    "# then we take out only the window we want...\n",
    "LoadSeconds = LoadSeconds[StartTime:EndTime,:]\n",
    "GenerationSeconds = GenerationSeconds[StartTime:EndTime,:]\n",
    "Load = LoadSeconds\n",
    "Generation = GenerationSeconds\n",
    "Origin_Load = LoadSeconds\n",
    "Origin_Generation = GenerationSeconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "############################################################\n",
    "#### Function for simulation################################\n",
    "############################################################\n",
    "############################################################\n",
    "\n",
    "def inverter_qp_injection(counter, Vk, Vkm1, gammakm1, solar_irr, VBP, Sbar, dv, T=1, lpf=1):\n",
    "    pk = 0\n",
    "    qk = 0\n",
    "    c = 0\n",
    "    q_avail = 0\n",
    "\n",
    "    solar_range = 5\n",
    "\n",
    "    Vmagk = abs(Vk)\n",
    "    Vmagkm1 = abs(Vkm1)\n",
    "    gammakcalc = (T*lpf*(Vmagk + Vmagkm1) - (T*lpf - 2)*gammakm1)/(2 + T*lpf)\n",
    "\n",
    "    if counter % dv == 0:\n",
    "        gammakused = gammakcalc\n",
    "    else :\n",
    "        gammakused = gammakm1\n",
    "\n",
    "    if solar_irr < solar_range:\n",
    "        pk = 0\n",
    "        qk = 0\n",
    "    elif solar_irr >= solar_range:\n",
    "        if gammakused <= VBP[2]:\n",
    "            pk = -solar_irr\n",
    "            q_avail = (Sbar**2 - pk**2)**(1/2)\n",
    "            if gammakused <= VBP[0]:\n",
    "                qk = 0\n",
    "            elif gammakused > VBP[0] and gammakused <= VBP[1]:\n",
    "                c = q_avail/(VBP[1] - VBP[0])\n",
    "                qk = c*(gammakused - VBP[0])\n",
    "            else:\n",
    "                qk = q_avail\n",
    "        elif gammakused > VBP[2] and gammakused < VBP[3]:\n",
    "            d = -solar_irr/(VBP[3] - VBP[2])\n",
    "            pk = -(d*(gammakused - VBP[2]) + solar_irr)\n",
    "            qk = (Sbar**2 - pk**2)**(1/2)\n",
    "        elif gammakused >= VBP[3]:\n",
    "            qk = Sbar\n",
    "            pk = 0\n",
    "    return qk,pk, gammakused\n",
    "    \n",
    "def voltage_observer(vk, vkm1, psikm1, epsilonkm1, ykm1, f_hp=1, f_lp=0.1, gain=1e5, T=1):\n",
    "    Vmagk = abs(vk)\n",
    "    Vmagkm1 = abs(vkm1)\n",
    "    psik = (Vmagk - Vmagkm1 - (f_hp*T/2-1)*psikm1)/(1+f_hp*T/2)\n",
    "    epsilonk = gain*(psik**2)\n",
    "    yk = (T*f_lp*(epsilonk + epsilonkm1) - (T*f_lp - 2)*ykm1)/(2 + T*f_lp)\n",
    "    return yk, psik, epsilonk\n",
    "\n",
    "def adaptive_control(delay, vk, vkmdelay, ukmdelay, thresh, yk):\n",
    "    if (yk > thresh):\n",
    "        uk = delay/2*k * ( vk**2 + vkmdelay**2 ) + ukmdelay\n",
    "    else:\n",
    "        uk = ukmdelay\n",
    "    return uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#support function\n",
    "def processing_state(V, G, L):\n",
    "    state = np.array([V, G, L]).T\n",
    "    result = np.zeros((60,3))\n",
    "    result[:state.shape[0],:state.shape[1]] = state #padding with zeros\n",
    "    state = result.copy()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anacoda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#this is the agent\n",
    "import tensorflow as tf\n",
    "EPS = 1e-6\n",
    "\n",
    "def build_graph(inputs, layer_sizes, non_linearlayer=False):\n",
    "    if type(inputs) is tf.Tensor:\n",
    "        inputs = [inputs]\n",
    "    \n",
    "    with tf.variable_scope('layer0'):\n",
    "        state = inputs[0]\n",
    "        lstm_cell = tf.contrib.rnn.LSTMCell(num_units=32, use_peepholes=True)\n",
    "        outputs, states = tf.nn.dynamic_rnn(lstm_cell, state, dtype=tf.float32)\n",
    "        state0 = tf.layers.dense(states.h, 30)\n",
    "        if len(inputs) != 1:\n",
    "            action = inputs[1]\n",
    "            action0 = tf.layers.dense(action, 30)\n",
    "            layer = action0 + state0\n",
    "        else: \n",
    "            layer = state0\n",
    "        layer = tf.nn.relu(layer)\n",
    "    \n",
    "    for i_layer, size in enumerate(layer_sizes, 1):\n",
    "        with tf.variable_scope('layer{0}'.format(i_layer)):\n",
    "            layer = tf.layers.dense(layer, size)\n",
    "            if i_layer < len(layer_sizes) - 1:\n",
    "                layer = tf.nn.relu(layer)\n",
    "    \n",
    "    if non_linearlayer==True:\n",
    "        layer = tf.nn.tanh(layer)\n",
    "    \n",
    "    return layer\n",
    "\n",
    "class NNFunction():\n",
    "    def __init__(self, name, input_pls, hidden_layer_sizes):\n",
    "        self._name = name\n",
    "        self._input_pls = input_pls\n",
    "        self._layer_sizes = list(hidden_layer_sizes) + [1]\n",
    "        self._output_t = self.get_output_for(*self._input_pls)\n",
    "    def get_output_for(self, *inputs, reuse=False):\n",
    "        with tf.variable_scope(self._name, reuse=reuse):\n",
    "            value_t = build_graph(inputs=inputs, layer_sizes=self._layer_sizes)\n",
    "        return value_t\n",
    "    \n",
    "    def get_params_internal(self):\n",
    "\n",
    "        scope = tf.get_variable_scope().name\n",
    "        scope += '/' + self._name + '/' if len(scope) else self._name + '/'\n",
    "        return tf.get_collection(\n",
    "            tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope\n",
    "        )\n",
    "\n",
    "class NNQFunction(NNFunction):\n",
    "    def __init__(self, hidden_layer_sizes=(30,30), name='qf'):\n",
    "        self._Da = 4\n",
    "        self._Do = [60,3]\n",
    "        self._obs_pl = tf.placeholder(tf.float32, shape=[None]+ self._Do, name='observation')\n",
    "        self._action_pl = tf.placeholder(tf.float32, shape=[None, self._Da], name='action')\n",
    "        super(NNQFunction, self).__init__(name, (self._obs_pl, self._action_pl), hidden_layer_sizes)\n",
    "\n",
    "#############################################################        \n",
    "    \n",
    "class Policy(NNFunction):\n",
    "    def __init__(self, hidden_layer_sizes=(30,30), reparameterize=False, name='policy', squash=True):\n",
    "        self._name = name\n",
    "        self._Do = [60,3]\n",
    "        self._Da = 4\n",
    "        self._obs_pl = tf.placeholder(tf.float32, shape=[None] + self._Do, name='observation')\n",
    "        self._layer_sizes = hidden_layer_sizes\n",
    "        super(Policy, self).__init__(name, (self._obs_pl,), hidden_layer_sizes)\n",
    "        \n",
    "    def actions_for(self, observations, reuse=tf.AUTO_REUSE):\n",
    "        name = self._name\n",
    "        with tf.variable_scope(name, reuse=reuse):\n",
    "            actions = build_graph(inputs=observations, layer_sizes=self._layer_sizes, non_linearlayer=True)        \n",
    "        return actions    \n",
    "    \n",
    "    def get_params_internal(self):\n",
    "\n",
    "        scope = tf.get_variable_scope().name\n",
    "        scope += '/' + self._name + '/' if len(scope) else self._name + '/'\n",
    "        return tf.get_collection(\n",
    "            tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope\n",
    "        )\n",
    "    \n",
    "    def _squash_correction(self, actions):\n",
    "        if not self._squash: return 0\n",
    "        return tf.reduce_sum(tf.log(1 - tf.tanh(actions) ** 2 + EPS), axis=1)\n",
    "    \n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "class agent():\n",
    "    def __init__(self, sess, observations_ph, next_observations_ph, rewards_ph, actions_ph, terminals_ph, name='agent'):\n",
    "        self._observations_ph = observations_ph\n",
    "        self._next_observations_ph = next_observations_ph\n",
    "        self._rewards_ph = rewards_ph\n",
    "        self._actions_ph= actions_ph\n",
    "        self._terminals_ph = terminals_ph\n",
    "        \n",
    "        self._discount = 0.99\n",
    "        self._tau = 0.01\n",
    "        \n",
    "        self._qf_lr = 0.1\n",
    "        self._vf_lr = 0.1\n",
    "        self._policy_lr = 0.01\n",
    "        self._action_prior = 'Normal'\n",
    "        self._reparameterize = False\n",
    "        self._sess = sess\n",
    "        self._training_ops = []\n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            self._qf = NNQFunction((30,30), 'qf')\n",
    "            self._policy = Policy(hidden_layer_sizes=(30,30))\n",
    "            self._init_critic_update()\n",
    "            self._init_actor_update()\n",
    "            self._init_target_ops()\n",
    "            \n",
    "        uninit_vars = []\n",
    "        for var in tf.global_variables():\n",
    "            try:\n",
    "                self._sess.run(var)\n",
    "            except tf.errors.FailedPreconditionError:\n",
    "                uninit_vars.append(var)\n",
    "        self._sess.run(tf.variables_initializer(uninit_vars))\n",
    "        \n",
    "        self._init_training()\n",
    "        \n",
    "    def _init_critic_update(self):\n",
    "        self._qf_t = self._qf.get_output_for(self._observations_ph, self._actions_ph, reuse=True)\n",
    "        \n",
    "        with tf.variable_scope('target_policy'):\n",
    "            actions = self._policy.actions_for(self._next_observations_ph)\n",
    "            self._policy_target_params = self._policy.get_params_internal()\n",
    "        \n",
    "        with tf.variable_scope('target_qf'):\n",
    "            self._qf_t_next = self._qf.get_output_for(self._next_observations_ph, actions, reuse=True)        \n",
    "            self._qf_target_params = self._qf.get_params_internal()\n",
    "        ys = tf.stop_gradient(\n",
    "            self._rewards_ph +\n",
    "            (1 - self._terminals_ph) * self._discount * self._qf_t_next)  \n",
    "        \n",
    "        self._td_loss_t = 0.5 * tf.reduce_mean((ys - self._qf_t)**2)\n",
    "        qf_train_op = tf.train.AdamOptimizer(self._qf_lr).minimize(\n",
    "            loss=self._td_loss_t,\n",
    "            var_list=self._qf.get_params_internal()\n",
    "        )\n",
    "        self._training_ops.append(qf_train_op)\n",
    "        \n",
    "    def _init_actor_update(self):\n",
    "        self._action = self._policy.actions_for(self._observations_ph, reuse=True)\n",
    "        self._policy_params = self._policy.get_params_internal()\n",
    "        self._qf_t = self._qf.get_output_for(self._observations_ph, self._actions_ph, reuse=True)\n",
    "        self._qf_params = self._qf_t.get_params_internal()\n",
    "        \n",
    "        q_grads = tf.gradients(self._qf_t, self._action_ph)\n",
    "        policy_grads = tf.gradients(actions, self._observations_ph)\n",
    "        \n",
    "        grads = tf.multiply(q_grads, policy_grads)\n",
    "        self.actor_gradients = list(map(lambda x: tf.div(x, 5), grads))\n",
    "        policy_train_op = tf.train.AdamOptimizer(self._policy_lr).apply_gradients(zip(self.actor_gradients, self._policy.get_params_internal()))\n",
    "        self._training_ops.append(policy_train_op)        \n",
    "        self._action = actions\n",
    "        \n",
    "    def _init_target_ops(self):\n",
    "        \"\"\"Create tensorflow operations for updating target value function.\"\"\"\n",
    "\n",
    "        source_params = self._qf_params\n",
    "        target_params = self._qf_target_params\n",
    "\n",
    "        self._target_ops_qf = [\n",
    "            tf.assign(target, (1 - self._tau) * target + self._tau * source)\n",
    "            for target, source in zip(target_params, source_params)\n",
    "        ]\n",
    "        \n",
    "        source_params_p = self._policy_params\n",
    "        target_params_p = self._policy_target_params\n",
    "\n",
    "        self._target_ops_p = [\n",
    "            tf.assign(target, (1 - self._tau) * target + self._tau * source)\n",
    "            for target, source in zip(target_params_p, source_params_p)\n",
    "        ]\n",
    "\n",
    "    def _init_training(self):\n",
    "        self._sess.run(self._target_ops)\n",
    "\n",
    "    def do_training(self, batch):\n",
    "        \"\"\"Runs the operations for updating training and target ops.\"\"\"\n",
    "\n",
    "        feed_dict = self._get_feed_dict(batch)\n",
    "        self._sess.run(self._training_ops[0], feed_dict)\n",
    "        self._sess.run(self._training_ops[1], feed_dict)\n",
    "        self._sess.run(self._target_ops_qf)\n",
    "        self._sess.run(self._target_ops_p)\n",
    "\n",
    "    def _get_feed_dict(self, batch):\n",
    "        \"\"\"Construct TensorFlow feed_dict from sample batch.\"\"\"\n",
    "\n",
    "        feed_dict = {\n",
    "            self._observations_ph: batch['observations'],\n",
    "            self._actions_ph: batch['actions'],\n",
    "            self._next_observations_ph: batch['next_observations'],\n",
    "            self._rewards_ph: batch['rewards'],\n",
    "            self._terminals_ph: batch['terminals'],\n",
    "        }\n",
    "        return feed_dict\n",
    "   \n",
    "    def action_respond(self, obs):\n",
    "        action = self._action\n",
    "        a = self._sess.run([action], feed_dict={observations_ph: obs})[0][0]\n",
    "        return a\n",
    "    \n",
    "def init_placeholder():\n",
    "    observations_ph = tf.placeholder(tf.float32, shape=(None, 60, 3), name='observation')\n",
    "    next_observations_ph = tf.placeholder(tf.float32, shape=(None, 60, 3), name='next_observation')\n",
    "    rewards_ph = tf.placeholder(tf.float32, shape=(None, 1), name='reward')\n",
    "    actions_ph = tf.placeholder(tf.float32, shape=(None, 4), name='action')\n",
    "    terminals_ph = tf.placeholder(tf.float32, shape=(None, 1), name='terminal')\n",
    "    return observations_ph, next_observations_ph, rewards_ph, actions_ph, terminals_ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable agent/target_qf/qf/layer0/rnn/lstm_cell/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bf260c343184>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mobservations_ph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_observations_ph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards_ph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions_ph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminals_ph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_placeholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservations_ph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_observations_ph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards_ph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions_ph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminals_ph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-dbf63fa59a77>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess, observations_ph, next_observations_ph, rewards_ph, actions_ph, terminals_ph, name)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNNQFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'qf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_policy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPolicy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_critic_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_actor_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_target_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-dbf63fa59a77>\u001b[0m in \u001b[0;36m_init_critic_update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'target_qf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qf_t_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_observations_ph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qf_target_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         ys = tf.stop_gradient(\n",
      "\u001b[1;32m<ipython-input-1-dbf63fa59a77>\u001b[0m in \u001b[0;36mget_output_for\u001b[1;34m(self, reuse, *inputs)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_output_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[0mvalue_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layer_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalue_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-dbf63fa59a77>\u001b[0m in \u001b[0;36mbuild_graph\u001b[1;34m(inputs, layer_sizes, non_linearlayer)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mlstm_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_peepholes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mstate0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[1;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[0;32m    625\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m         dtype=dtype)\n\u001b[0m\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m     \u001b[1;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[1;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m       swap_memory=swap_memory)\n\u001b[0m\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m   \u001b[1;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations)\u001b[0m\n\u001b[0;32m   3222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3223\u001b[0m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3224\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3225\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3226\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[1;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2955\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[1;32m-> 2956\u001b[1;33m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[0;32m   2957\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2958\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[1;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2891\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m   2892\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2893\u001b[1;33m     \u001b[0mbody_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2894\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2895\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   3192\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[0;32m   3193\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[1;32m-> 3194\u001b[1;33m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3196\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[1;34m(time, output_ta_t, state)\u001b[0m\n\u001b[0;32m    793\u001b[0m           skip_conditionals=True)\n\u001b[0;32m    794\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m       \u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[1;31m# Pack state if using state tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m     \u001b[0mcall_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[1;31m# method.  See the class docstring for more details.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     return base_layer.Layer.__call__(self, inputs, state, scope=scope,\n\u001b[1;32m--> 339\u001b[1;33m                                      *args, **kwargs)\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_shape'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m           \u001b[1;31m# Note: not all sub-classes of Layer call Layer.__init__ (especially\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, inputs_shape)\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_depth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m         partitioner=maybe_partitioner)\n\u001b[0m\u001b[0;32m    768\u001b[0m     self._bias = self.add_variable(\n\u001b[0;32m    769\u001b[0m         \u001b[0m_BIAS_VARIABLE_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36madd_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner)\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m             partitioner=partitioner)\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minit_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    434\u001b[0m     new_variable = getter(\n\u001b[0;32m    435\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         **kwargs_for_getter)\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1315\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m       constraint=constraint)\n\u001b[0m\u001b[0;32m   1318\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1319\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1077\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Apps\\Anacoda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    749\u001b[0m       raise ValueError(\"Variable %s does not exist, or was not created with \"\n\u001b[0;32m    750\u001b[0m                        \u001b[1;34m\"tf.get_variable(). Did you mean to set \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m                        \"reuse=tf.AUTO_REUSE in VarScope?\" % name)\n\u001b[0m\u001b[0;32m    752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minitializing_from_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m       raise ValueError(\"Shape of a new variable (%s) must be fully defined, \"\n",
      "\u001b[1;31mValueError\u001b[0m: Variable agent/target_qf/qf/layer0/rnn/lstm_cell/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?"
     ]
    }
   ],
   "source": [
    "observations_ph, next_observations_ph, rewards_ph, actions_ph, terminals_ph = init_placeholder()\n",
    "sess = tf.Session()\n",
    "agent = agent(sess, observations_ph, next_observations_ph, rewards_ph, actions_ph, terminals_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "\"\"\"import numpy as np \n",
    "policy = GaussianPolicy()\n",
    "observations_ph, next_observations_ph, rewards_ph, actions_ph, terminals_ph = init_placeholder()\n",
    "action = policy.actions_for(observations_ph, with_log_pis = False)\n",
    "#testing\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    a = sess.run([action], feed_dict={observations_ph: np.random.random_sample((5,60,3))})[0]\n",
    "    print(a)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "totalPoints = [[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "############################################\n",
    "########### INIT FOR AGENT #################\n",
    "############################################\n",
    "\n",
    "#init action\n",
    "oldAction = []\n",
    "action = []\n",
    "\n",
    "#init state\n",
    "oldState = []\n",
    "state = []\n",
    "\n",
    "#init reward\n",
    "reward = None\n",
    "\n",
    "mb_state=[]\n",
    "mb_action=[]\n",
    "mb_reward=[]\n",
    "mb_nextstate=[]\n",
    "buffer = ReplayBuffer(300)\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "for ep in range(50):\n",
    "    Load = Origin_Load.copy()\n",
    "    Generation = Origin_Generation.copy()\n",
    "    #this is for permutate the Load and Generation profile on each node\n",
    "    #Load = np.random.permutation(Load.T).T\n",
    "    #Generation = np.random.permutation(Generation.T).T\n",
    "\n",
    "    #this is to permutate the Load and Generation profile\n",
    "    #temp = np.copy(Load[:, 0:Number_of_Inverters])\n",
    "    #Load[:, 0:Number_of_Inverters] = Load[:, Number_of_Inverters:Number_of_Inverters*2]\n",
    "    #Load[:, Number_of_Inverters:Number_of_Inverters*2] = temp\n",
    "    #temp = np.copy(Generation[:, 0:Number_of_Inverters])\n",
    "    #Generation[:, 0:Number_of_Inverters] = Generation[:, Number_of_Inverters:Number_of_Inverters*2]\n",
    "    #Generation[:, Number_of_Inverters:Number_of_Inverters*2] = temp\n",
    "\n",
    "    #Create noise vector\n",
    "    Noise = np.empty([TotalTimeSteps, TotalLoads])\n",
    "    for node in range(TotalLoads):\n",
    "        Noise[:,node] = np.random.randn(TotalTimeSteps) \n",
    "\n",
    "    #Add noise to loads\n",
    "    for node in range(TotalLoads):\n",
    "        Load[:,node] = Load[:,node] + NoiseMultiplyer*Noise[:,node]\n",
    "\n",
    "    if NoiseMultiplyer > 0:\n",
    "        print('Load Interpolation has been done. Noise was added to the load profile.') \n",
    "    else:\n",
    "        print('Load Interpolation has been done. No Noise was added to the load profile.') \n",
    "\n",
    "    MaxGenerationPossible = np.max(Generation, axis = 0)\n",
    "    sbar = MaxGenerationPossible\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #########################################################\n",
    "    ################### RESTART OPENDSS #####################\n",
    "    #########################################################\n",
    "    DSSStart = DSSStartup()\n",
    "    DSSText =DSSStart['dsstext']\n",
    "    DSSSolution = DSSStart['dsssolution']\n",
    "    DSSCircuit = DSSStart['dsscircuit']\n",
    "    DSSObj = DSSStart['dssobj']\n",
    "    DSSMon = DSSCircuit.Monitors\n",
    "    DSSText.command = 'Compile C:\\\\feeders\\\\feeder34_B_NR\\\\feeder34_B_NR.dss'\n",
    "    DSSSolution.Solve()\n",
    "    if not DSSSolution.Converged:\n",
    "        print('Initial Solution Not Converged. Check Model for Convergence')\n",
    "    else:\n",
    "        print('Initial Model Converged. Proceeding to Next Step.')\n",
    "        #Doing this solve command is required for GridPV, that is why the monitors\n",
    "        #go under a reset process\n",
    "        DSSMon.ResetAll\n",
    "        setSolutionParams(DSSObj,'daily',1,1,'off',1000000,30000)\n",
    "        #Easy process to get all names and count of loads, a trick to avoid\n",
    "        #some more lines of code\n",
    "        TotalLoads=DSSCircuit.Loads.Count\n",
    "        AllLoadNames=DSSCircuit.Loads.AllNames\n",
    "        print('OpenDSS Model Compliation Done.')\n",
    "\n",
    "    ############################################\n",
    "    ############ INIT NODES ####################\n",
    "    ############################################\n",
    "    nodes = {}\n",
    "    features = ['Voltage', 'Generation', 'P', 'Q']\n",
    "\n",
    "    for i in range(len(AllLoadNames)):\n",
    "        df = pd.DataFrame(columns=list(range(TotalTimeSteps)),index=features)\n",
    "        nodes[i] = df\n",
    "        nodes[i].loc['Generation'] = Generation[:,i]\n",
    "        nodes[i].loc['P'] = 0\n",
    "        nodes[i].loc['Q'] = 0\n",
    "\n",
    "    ################################################\n",
    "    ############ INIT INVERTERS ####################\n",
    "    ################################################\n",
    "    inverters = {}\n",
    "    features = ['VBP', 'FilterVoltage', 'Generation', 'sbar', 'P_inv', 'Q_inv' ,'counter', 'ime_output', 'ep_output', 'yk', 'upk','uqk']\n",
    "\n",
    "    offset = 5\n",
    "    numberofInverters = Number_of_Inverters\n",
    "\n",
    "    for i in range(len(AllLoadNames)):\n",
    "        inverters[i] = []\n",
    "        if offset-1 < i < numberofInverters + offset:\n",
    "            df = pd.DataFrame(columns=list(range(TotalTimeSteps)),index=features)\n",
    "            df.at['FilterVoltage', 0] = 0\n",
    "            df.loc['Generation'] = Generation[:,i]\n",
    "            df.loc['sbar'] = sbar[i]\n",
    "            df.loc['counter'] = 0\n",
    "            df.loc['ime_output'] = 0\n",
    "            df.loc['ep_output'] = 0\n",
    "            df.loc['yk'] = 0\n",
    "            df.loc['P_inv'] = 0\n",
    "            df.loc['Q_inv'] = 0\n",
    "            df.loc['upk'] = 0\n",
    "            df.loc['uqk'] = 0\n",
    "            inverters[i].append(df)\n",
    "\n",
    "    ############################################\n",
    "    ########### INIT VBPCURVE ##################\n",
    "    ############################################\n",
    "    for i in range(len(AllLoadNames)):\n",
    "        for j in range(len(inverters[i])):\n",
    "            for k in range(TotalTimeSteps):\n",
    "                inverters[i][j].at['VBP',k] = np.array([1.01, 1.03, 1.03, 1.05])\n",
    "\n",
    "    VBPcounter = [0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "    controlInv = list(range(7,8))    \n",
    "    points = [0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    terminal = False\n",
    "    \n",
    "    for timeStep in range(TotalTimeSteps):\n",
    "        VBPcounter = [x+1 for x in VBPcounter] \n",
    "        ####################################################\n",
    "        ################ run the simulation ################\n",
    "        ####################################################\n",
    "        #for the first steps, we just init voltage value, no pq injection\n",
    "        if timeStep == 0:\n",
    "            for node in range(len(AllLoadNames)):\n",
    "                nodeName = AllLoadNames[node]\n",
    "                setLoadInfo(DSSObj, [nodeName], 'kw', [Load[timeStep, node]])\n",
    "                setLoadInfo(DSSObj, [nodeName], 'kvar', [pf_converted*Load[timeStep, node]])\n",
    "        else:\n",
    "            for node in range(len(AllLoadNames)):\n",
    "                nodeName = AllLoadNames[node]\n",
    "                setLoadInfo(DSSObj, [nodeName], 'kw', [Load[timeStep, node] + nodes[node].at['P', timeStep-1]])\n",
    "                setLoadInfo(DSSObj, [nodeName], 'kvar', [pf_converted*Load[timeStep, node] + nodes[node].at['Q', timeStep-1]])\n",
    "\n",
    "        DSSSolution.Solve()\n",
    "        if (not DSSSolution.Converged):\n",
    "            print('Solution Not Converged at Step:', timeStep)\n",
    "\n",
    "        #get the voltage info\n",
    "        nodeInfo = getLoadInfo(DSSObj, [])\n",
    "        #distribute voltage to node\n",
    "        for i in range(len(nodes)):\n",
    "            node = nodes[i]\n",
    "            node.at['Voltage', timeStep] = nodeInfo[i]['voltagePU']\n",
    "            if timeStep == 0 or timeStep == 1:\n",
    "                node.at['Voltage', timeStep] = 1\n",
    "        #############################################################\n",
    "        #############################################################\n",
    "        #############################################################\n",
    "        if timeStep == TimeStepOfHack:\n",
    "            for node in range(len(AllLoadNames)):\n",
    "                if inverters[node] != []:\n",
    "                    inverter = inverters[node][0]\n",
    "                    #create new inverter\n",
    "                    hackedInv = copy.deepcopy(inverter)\n",
    "                    for k in range(timeStep, TotalTimeSteps):\n",
    "                        hackedInv.at['VBP',k] = np.array([1.01, 1.015, 1.015, 1.02])\n",
    "\n",
    "                    hackedInv.loc['sbar'][timeStep:] = hackedInv.loc['sbar'][timeStep:]*PercentHacked[node]\n",
    "                    hackedInv.loc['Generation'][timeStep:] = hackedInv.loc['Generation'][timeStep:]*PercentHacked[node]\n",
    "                    inverters[node].append(hackedInv)\n",
    "                    #generation and sbar change on the original inverter\n",
    "                    inverter.loc['sbar'][timeStep:] = inverter.loc['sbar'][timeStep:]*(1-PercentHacked[node])\n",
    "                    inverter.loc['Generation'][timeStep:] = inverter.loc['Generation'][timeStep:]*(1-PercentHacked[node])\n",
    "        ########################################################################\n",
    "        ########################################################################\n",
    "        ########################################################################\n",
    "        \n",
    "        if timeStep == TotalTimeSteps-1:\n",
    "            terminal = True\n",
    "            \n",
    "        if timeStep != 0:\n",
    "            for node in range(len(AllLoadNames)):\n",
    "                #if we have inverters at that node then...\n",
    "                if inverters[node] != []:\n",
    "                    invertersNode = inverters[node] #get the list of inverters at that node\n",
    "                    for inverter in invertersNode: #get an inverter at that node\n",
    "                        #increase the counter\n",
    "                        inverter.at['counter',timeStep] = inverter.at['counter',timeStep-1] + 1\n",
    "                        if inverter.at['counter',timeStep-1] == Delay_VoltageSampling[node]:\n",
    "                            inverter.at['counter',timeStep] = 1\n",
    "                            \n",
    "                        #get State\n",
    "                        if (node in controlInv) and (inverter is invertersNode[0]):\n",
    "                            if VBPcounter[node-offset] == Delay_VBPCurveShift[node] or terminal == True:\n",
    "                                if terminal == False:\n",
    "                                    length = Delay_VBPCurveShift[node]\n",
    "                                    V = nodes[node].loc['Voltage',timeStep-length+1:timeStep]\n",
    "                                    G = inverter.loc['Generation', timeStep-length+1:timeStep] \n",
    "                                    L = Load[timeStep-length+1:timeStep+1, node]\n",
    "                                else:\n",
    "                                    length = VBPcounter[node-offset]\n",
    "                                    V = nodes[node].loc['Voltage',timeStep-length+1:]\n",
    "                                    G = inverter.loc['Generation', timeStep-length+1:]\n",
    "                                    L = Load[timeStep-length+1:, node]\n",
    "                                    \n",
    "                                oldState = state\n",
    "                                state = processing_state(V,G,L)\n",
    "                                #reset VBPcounter\n",
    "                                VBPcounter[node-offset] = 0\n",
    "                                #store action                        \n",
    "                                oldAction = copy.deepcopy(action)\n",
    "                                \n",
    "                                #get Action from Agent\n",
    "                                action = agent.action_respond(state.reshape((1,60,3)))\n",
    "                                #apply strict boundary\n",
    "                                if action[1] < action[0]:\n",
    "                                    action[0] = action[1]\n",
    "                                if action[3] < action[2]:\n",
    "                                    action[2] = action[3]\n",
    "                                for k in range(timeStep, TotalTimeSteps):\n",
    "                                    inverter.at['VBP',k] = copy.deepcopy(action*0.1 + 1)\n",
    "                                \n",
    "                                #reward\n",
    "                                #caculate yk for that inverter\n",
    "                                inverter.at['yk', timeStep], inverter.at['ime_output', timeStep], inverter.at['ep_output', timeStep] = voltage_observer(\n",
    "                                         nodes[node].at['Voltage', timeStep], \n",
    "                                         nodes[node].at['Voltage', timeStep-1],\n",
    "                                         inverter.at['ime_output', timeStep-1], \n",
    "                                         inverter.at['ep_output', timeStep-1], \n",
    "                                         inverter.at['yk', timeStep-1])\n",
    "\n",
    "                                numberYks = inverter.loc['yk', timeStep-length+1:timeStep]\n",
    "                                numberYks = numberYks - 0.25\n",
    "                                numberYks = numberYks[numberYks > 0]\n",
    "                                reward = - sum(numberYks**2)\n",
    "                                \n",
    "                                #sum of reward for that ep\n",
    "                                points[node-offset] += reward\n",
    "                                \n",
    "                                \n",
    "                                if oldAction != [] and oldState != []:\n",
    "                                    if terminal: \n",
    "                                        ter = 1\n",
    "                                    else:\n",
    "                                        ter = 0\n",
    "                                    buffer.add(oldState.reshape((60,3)), oldAction, np.array([reward]), np.array([ter]), state.reshape((60,3)))\n",
    "                                \n",
    "                                if buffer.size() > BATCH_SIZE:\n",
    "                                    batch = {}\n",
    "                                    mb_state, mb_action, mb_reward, mb_ter, mb_nextstate = buffer.sample_batch(BATCH_SIZE)\n",
    "                                    batch['observations'] = mb_state\n",
    "                                    batch['actions'] = mb_action\n",
    "                                    batch['rewards'] = mb_reward\n",
    "                                    batch['next_observations'] = mb_nextstate\n",
    "                                    batch['rewards'] = mb_reward\n",
    "                                    batch['terminals'] = mb_ter\n",
    "                                    start_time_train = time.time()\n",
    "                                    agent.do_training(batch)\n",
    "                                    print(\"--- %s seconds ---\" % (time.time() - start_time_train))\n",
    "                        #################################################                        \n",
    "                        #################################################\n",
    "                        #execute action\n",
    "                        inverter.at['Q_inv', timeStep], inverter.at['P_inv', timeStep], inverter.at['FilterVoltage', timeStep] = inverter_qp_injection(\n",
    "                            inverter.at['counter',timeStep],\n",
    "                            nodes[node].at['Voltage', timeStep],\n",
    "                            nodes[node].at['Voltage', timeStep-1],\n",
    "                            inverter.at['FilterVoltage', timeStep-1],\n",
    "                            inverter.at['Generation', timeStep],\n",
    "                            inverter.at['VBP', timeStep],\n",
    "                            inverter.at['sbar', timeStep],\n",
    "                            Delay_VoltageSampling[node])\n",
    "                        \n",
    "                        inverter.at['yk', timeStep], inverter.at['ime_output', timeStep], inverter.at['ep_output', timeStep] = voltage_observer(\n",
    "                                         nodes[node].at['Voltage', timeStep], \n",
    "                                         nodes[node].at['Voltage', timeStep-1],\n",
    "                                         inverter.at['ime_output', timeStep-1], \n",
    "                                         inverter.at['ep_output', timeStep-1], \n",
    "                                         inverter.at['yk', timeStep-1])\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        #caculate P Q injection at the node\n",
    "                        nodes[node].at['P', timeStep] += inverter.at['P_inv', timeStep]\n",
    "                        nodes[node].at['Q', timeStep] += inverter.at['Q_inv', timeStep]\n",
    "\n",
    "    ######### drawing #####################\n",
    "    \n",
    "    for i in range(len(points)):\n",
    "        totalPoints[i].append(points[i])\n",
    "    print(max(totalPoints[7-offset]))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    f = plt.figure()\n",
    "    f.set_figheight(4)\n",
    "    f.set_figwidth(20)\n",
    "    f.add_subplot(1,4,1)\n",
    "    plt.plot(nodes[7].loc['Voltage'], marker='o')\n",
    "    \n",
    "    for i in range(5,18):\n",
    "        x = inverters[i][0].loc['VBP']\n",
    "        y=np.zeros([len(x),x[0].shape[0]])\n",
    "        for i in range(len(x)):\n",
    "            y[i,:] = x[i]\n",
    "        f.add_subplot(1,4,2)\n",
    "        plt.plot(y[:,0], 'r')\n",
    "        plt.plot(y[:,1], 'y')\n",
    "        plt.plot(y[:,2], 'b')\n",
    "        plt.plot(y[:,3], 'k')\n",
    "    \n",
    "    f.add_subplot(1,4,3)\n",
    "    for i in range(7,8):\n",
    "        yk = inverters[i][0].loc['yk']\n",
    "        plt.plot(yk)\n",
    "    plt.axhline(y=0.25, color='r', linestyle='-')\n",
    "    f.add_subplot(1,4,4)\n",
    "    plt.plot(totalPoints[7-offset])\n",
    "    plt.show(block=True)\n",
    "    f.savefig(str(ep) + '.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
