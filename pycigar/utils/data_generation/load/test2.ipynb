{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from init import *\n",
    "from src.process_data import read_initial_data\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_files(csv):\n",
    "    orig_df = pd.read_csv(csv, names=['file_name', 'kW']).iloc[1:, :]\n",
    "    df = orig_df.drop_duplicates(subset='kW', keep='first')\n",
    "    filenames = df.iloc[:, 0].tolist()\n",
    "    order = df.iloc[:, 1].tolist()\n",
    "    data_prefix_new = \"C:\\\\Users\\\\kathl\\Desktop\\\\Github\\\\ceds-cigar\\\\pycigar\\\\utils\\\\data_generation\\\\load\\\\data\\\\LS\\\\\"\n",
    "\n",
    "    filenames = [data_prefix_new + s + '.csv' for s in filenames]\n",
    "    order = [float(s) for s in order]\n",
    "    \n",
    "    return filenames, order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames, order = clean_files('order.csv')\n",
    "dss_kw = []\n",
    "\n",
    "load_gen = LoadGenerator(filenames[:10], dss_kw, order[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prefix = \"C:\\\\Users\\\\kathl\\Desktop\\\\Github\\\\ceds-cigar\\\\pycigar\\\\utils\\\\data_generation\\\\load\\\\data\"\n",
    "# data = [data_prefix + '\\\\7_MWp_P.csv', data_prefix + '\\\\10_MWp_P.csv', data_prefix + '\\\\12_MWp_P.csv', data_prefix + '\\\\19_MWp_P.csv']\n",
    "ls_prefix = data_prefix + '\\\\LS\\\\'\n",
    "# #new_file = [ls_prefix + 'Tran_bp_701_77073_5022.csv', ls_prefix + 'Tran_bp_701_77073_5025.csv', ls_prefix + 'Tran_bp_701_77073_5034.csv', ls_prefix + 'Tran_bp_701_77073_5035.csv']\n",
    "# new_file = [ls_prefix + 'Tran_dj_388104_1816_5022.csv', ls_prefix + 'Tran_dj_367162_1816_5025.csv', ls_prefix + 'Tran_dj_357546_1816_5025.csv', ls_prefix + 'Tran_dj_388082_1816_5024.csv']\n",
    "\n",
    "# # dss_kw = [0.14, 0.16, 0.18, 0.07, 0.09] #assumes input in kw\n",
    "dss_kw = []\n",
    "load_gen = LoadGenerator(filenames, dss_kw, order) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = load_gen.generate_load()\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018-01-01 09:00:00</th>\n",
       "      <th>3.564162733767376</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 09:05:00</td>\n",
       "      <td>3.895448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 09:10:00</td>\n",
       "      <td>3.455129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 09:15:00</td>\n",
       "      <td>3.452201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 09:20:00</td>\n",
       "      <td>3.294040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 09:25:00</td>\n",
       "      <td>3.357383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01 09:30:00</td>\n",
       "      <td>2.910566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-01 09:35:00</td>\n",
       "      <td>3.322887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-01 09:40:00</td>\n",
       "      <td>2.912173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-01 09:45:00</td>\n",
       "      <td>3.131233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-01 09:50:00</td>\n",
       "      <td>3.075153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-01 09:55:00</td>\n",
       "      <td>3.072155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-01 10:00:00</td>\n",
       "      <td>2.699170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-01 10:05:00</td>\n",
       "      <td>3.014097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-01 10:10:00</td>\n",
       "      <td>2.776341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-01 10:15:00</td>\n",
       "      <td>3.174010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-01 10:20:00</td>\n",
       "      <td>3.063571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-01 10:25:00</td>\n",
       "      <td>2.788046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-01 10:30:00</td>\n",
       "      <td>3.184952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-01 10:35:00</td>\n",
       "      <td>2.598388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-01 10:40:00</td>\n",
       "      <td>2.699441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-01 10:45:00</td>\n",
       "      <td>2.683935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-01 10:50:00</td>\n",
       "      <td>2.515731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-01-01 10:55:00</td>\n",
       "      <td>3.092188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-01-01 11:00:00</td>\n",
       "      <td>2.766621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-01-01 11:05:00</td>\n",
       "      <td>3.036361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-01-01 11:10:00</td>\n",
       "      <td>2.623871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-01-01 11:15:00</td>\n",
       "      <td>2.237609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-01-01 11:20:00</td>\n",
       "      <td>3.022708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-01-01 11:25:00</td>\n",
       "      <td>2.572162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-01-01 11:30:00</td>\n",
       "      <td>2.966927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018-01-01 11:35:00</td>\n",
       "      <td>2.934634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018-01-01 11:40:00</td>\n",
       "      <td>2.727015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018-01-01 11:45:00</td>\n",
       "      <td>3.283130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018-01-01 11:50:00</td>\n",
       "      <td>2.394839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018-01-01 11:55:00</td>\n",
       "      <td>3.359789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018-01-01 12:00:00</td>\n",
       "      <td>3.074699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2018-01-01 12:05:00</td>\n",
       "      <td>2.736417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2018-01-01 12:10:00</td>\n",
       "      <td>2.402291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018-01-01 12:15:00</td>\n",
       "      <td>2.511415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2018-01-01 12:20:00</td>\n",
       "      <td>2.566854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2018-01-01 12:25:00</td>\n",
       "      <td>2.815146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2018-01-01 12:30:00</td>\n",
       "      <td>2.239926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2018-01-01 12:35:00</td>\n",
       "      <td>2.470667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2018-01-01 12:40:00</td>\n",
       "      <td>3.221721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2018-01-01 12:45:00</td>\n",
       "      <td>3.125993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2018-01-01 12:50:00</td>\n",
       "      <td>2.624690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2018-01-01 12:55:00</td>\n",
       "      <td>2.904214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2018-01-01 13:00:00</td>\n",
       "      <td>2.605918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2018-01-01 13:05:00</td>\n",
       "      <td>2.121254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2018-01-01 13:10:00</td>\n",
       "      <td>2.492633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2018-01-01 13:15:00</td>\n",
       "      <td>1.977744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2018-01-01 13:20:00</td>\n",
       "      <td>2.644864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2018-01-01 13:25:00</td>\n",
       "      <td>2.782739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2018-01-01 13:30:00</td>\n",
       "      <td>1.921271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2018-01-01 13:35:00</td>\n",
       "      <td>2.743885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2018-01-01 13:40:00</td>\n",
       "      <td>2.769310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2018-01-01 13:45:00</td>\n",
       "      <td>2.119436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2018-01-01 13:50:00</td>\n",
       "      <td>3.003769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2018-01-01 13:55:00</td>\n",
       "      <td>2.434401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    2018-01-01 09:00:00  3.564162733767376\n",
       "0   2018-01-01 09:05:00           3.895448\n",
       "1   2018-01-01 09:10:00           3.455129\n",
       "2   2018-01-01 09:15:00           3.452201\n",
       "3   2018-01-01 09:20:00           3.294040\n",
       "4   2018-01-01 09:25:00           3.357383\n",
       "5   2018-01-01 09:30:00           2.910566\n",
       "6   2018-01-01 09:35:00           3.322887\n",
       "7   2018-01-01 09:40:00           2.912173\n",
       "8   2018-01-01 09:45:00           3.131233\n",
       "9   2018-01-01 09:50:00           3.075153\n",
       "10  2018-01-01 09:55:00           3.072155\n",
       "11  2018-01-01 10:00:00           2.699170\n",
       "12  2018-01-01 10:05:00           3.014097\n",
       "13  2018-01-01 10:10:00           2.776341\n",
       "14  2018-01-01 10:15:00           3.174010\n",
       "15  2018-01-01 10:20:00           3.063571\n",
       "16  2018-01-01 10:25:00           2.788046\n",
       "17  2018-01-01 10:30:00           3.184952\n",
       "18  2018-01-01 10:35:00           2.598388\n",
       "19  2018-01-01 10:40:00           2.699441\n",
       "20  2018-01-01 10:45:00           2.683935\n",
       "21  2018-01-01 10:50:00           2.515731\n",
       "22  2018-01-01 10:55:00           3.092188\n",
       "23  2018-01-01 11:00:00           2.766621\n",
       "24  2018-01-01 11:05:00           3.036361\n",
       "25  2018-01-01 11:10:00           2.623871\n",
       "26  2018-01-01 11:15:00           2.237609\n",
       "27  2018-01-01 11:20:00           3.022708\n",
       "28  2018-01-01 11:25:00           2.572162\n",
       "29  2018-01-01 11:30:00           2.966927\n",
       "30  2018-01-01 11:35:00           2.934634\n",
       "31  2018-01-01 11:40:00           2.727015\n",
       "32  2018-01-01 11:45:00           3.283130\n",
       "33  2018-01-01 11:50:00           2.394839\n",
       "34  2018-01-01 11:55:00           3.359789\n",
       "35  2018-01-01 12:00:00           3.074699\n",
       "36  2018-01-01 12:05:00           2.736417\n",
       "37  2018-01-01 12:10:00           2.402291\n",
       "38  2018-01-01 12:15:00           2.511415\n",
       "39  2018-01-01 12:20:00           2.566854\n",
       "40  2018-01-01 12:25:00           2.815146\n",
       "41  2018-01-01 12:30:00           2.239926\n",
       "42  2018-01-01 12:35:00           2.470667\n",
       "43  2018-01-01 12:40:00           3.221721\n",
       "44  2018-01-01 12:45:00           3.125993\n",
       "45  2018-01-01 12:50:00           2.624690\n",
       "46  2018-01-01 12:55:00           2.904214\n",
       "47  2018-01-01 13:00:00           2.605918\n",
       "48  2018-01-01 13:05:00           2.121254\n",
       "49  2018-01-01 13:10:00           2.492633\n",
       "50  2018-01-01 13:15:00           1.977744\n",
       "51  2018-01-01 13:20:00           2.644864\n",
       "52  2018-01-01 13:25:00           2.782739\n",
       "53  2018-01-01 13:30:00           1.921271\n",
       "54  2018-01-01 13:35:00           2.743885\n",
       "55  2018-01-01 13:40:00           2.769310\n",
       "56  2018-01-01 13:45:00           2.119436\n",
       "57  2018-01-01 13:50:00           3.003769\n",
       "58  2018-01-01 13:55:00           2.434401"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(filenames[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 09:00:00    13.151923\n",
       "2018-01-01 09:05:00    13.214165\n",
       "2018-01-01 09:10:00    13.572002\n",
       "2018-01-01 09:15:00    12.709069\n",
       "2018-01-01 09:20:00    11.340763\n",
       "2018-01-01 09:25:00    10.933582\n",
       "2018-01-01 09:30:00    10.546115\n",
       "2018-01-01 09:35:00     9.929989\n",
       "2018-01-01 09:40:00    10.176283\n",
       "2018-01-01 09:45:00    11.181200\n",
       "2018-01-01 09:50:00    12.344867\n",
       "2018-01-01 09:55:00    12.104966\n",
       "2018-01-01 10:00:00    11.903990\n",
       "2018-01-01 10:05:00    12.017866\n",
       "2018-01-01 10:10:00    11.919932\n",
       "2018-01-01 10:15:00    11.937812\n",
       "2018-01-01 10:20:00    12.086165\n",
       "2018-01-01 10:25:00    12.060266\n",
       "2018-01-01 10:30:00    12.357459\n",
       "2018-01-01 10:35:00    12.505395\n",
       "2018-01-01 10:40:00    12.820022\n",
       "2018-01-01 10:45:00    13.528153\n",
       "2018-01-01 10:50:00    13.252433\n",
       "2018-01-01 10:55:00    13.083521\n",
       "2018-01-01 11:00:00    13.686204\n",
       "2018-01-01 11:05:00    14.249901\n",
       "2018-01-01 11:10:00    14.349624\n",
       "2018-01-01 11:15:00    14.038558\n",
       "2018-01-01 11:20:00    13.460912\n",
       "2018-01-01 11:25:00    13.451838\n",
       "2018-01-01 11:30:00    14.753174\n",
       "2018-01-01 11:35:00    15.690481\n",
       "2018-01-01 11:40:00    15.570448\n",
       "2018-01-01 11:45:00    15.489555\n",
       "2018-01-01 11:50:00    14.647561\n",
       "2018-01-01 11:55:00    14.515695\n",
       "2018-01-01 12:00:00    14.838114\n",
       "2018-01-01 12:05:00    15.088632\n",
       "2018-01-01 12:10:00    15.386173\n",
       "2018-01-01 12:15:00    15.728441\n",
       "2018-01-01 12:20:00    15.663976\n",
       "2018-01-01 12:25:00    15.463634\n",
       "2018-01-01 12:30:00    14.339188\n",
       "2018-01-01 12:35:00    13.237078\n",
       "2018-01-01 12:40:00    13.603469\n",
       "2018-01-01 12:45:00    14.813815\n",
       "2018-01-01 12:50:00    15.472986\n",
       "2018-01-01 12:55:00    15.695824\n",
       "2018-01-01 13:00:00    15.485607\n",
       "2018-01-01 13:05:00    15.203355\n",
       "2018-01-01 13:10:00    14.891952\n",
       "2018-01-01 13:15:00    13.905531\n",
       "2018-01-01 13:20:00    13.195245\n",
       "2018-01-01 13:25:00    12.973652\n",
       "2018-01-01 13:30:00    15.098003\n",
       "2018-01-01 13:35:00    16.174039\n",
       "2018-01-01 13:40:00    16.504032\n",
       "2018-01-01 13:45:00    16.753429\n",
       "Freq: 5T, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x[0]\n",
    "x[0].resample('5T').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_gen.generate_load()\n",
    "for i in range(len(x)):\n",
    "    plt.plot(x[i])\n",
    "    plt.title(filenames[i])\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('output power')\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_gen.mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_names = os.listdir(\"C:\\\\Users\\\\kathl\\Desktop\\\\Github\\\\ceds-cigar\\\\pycigar\\\\utils\\\\data_generation\\\\load\\\\data\\\\LS\\\\\")\n",
    "data_prefix = \"C:\\\\Users\\\\kathl\\Desktop\\\\Github\\\\ceds-cigar\\\\pycigar\\\\utils\\\\data_generation\\\\load\\\\data\\\\LS\\\\\"\n",
    "len(file_names)\n",
    "for i in range(0, len(file_names)//30, 4):\n",
    "    curr_files = []\n",
    "    for j in range(0, 4):\n",
    "        curr_files.append(data_prefix + file_names[i + j])\n",
    "   \n",
    "    load_gen = LoadGenerator(curr_files, [])\n",
    "    hi = load_gen.generate_load(order)\n",
    "\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    for h in hi:\n",
    "        plt.plot(h)\n",
    "        #print(h.isnull().sum())\n",
    "    plt.title('generated profiles')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('watts (?)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendssdirect as dss\n",
    "import os\n",
    "from pycigar.utils.data_generation.load import LoadGenerator\n",
    "\n",
    "#file_names = os.listdir('/home/toanngo/Documents/GitHub/smart-inverter-adaptive-control/pycigar/data/701_5min_disag_noise/701/LS')\n",
    "file_names = os.listdir(\"C:\\\\Users\\\\kathl\\Desktop\\\\Github\\\\ceds-cigar\\\\pycigar\\\\data\\\\701_5min_disag_noise\\\\701\\\\LS\")\n",
    "#dss.run_command('Redirect /home/toanngo/Documents/GitHub/smart-inverter-adaptive-control/pycigar/data/701_5min_disag_noise/Master.dss')\n",
    "dss.run_command(\"Redirect C:\\\\Users\\\\kathl\\Desktop\\\\Github\\\\ceds-cigar\\\\pycigar\\\\data\\\\701_5min_disag_noise\\\\Master.dss\")\n",
    "load_df = dss.utils.loads_to_dataframe()\n",
    "output_dir = '/home/toanngo/Documents/GitHub/smart-inverter-adaptive-control/pycigar/data/701_5min_disag_noise/701/LS_shorten'\n",
    "output_dir = \"C:\\\\Users\\\\kathl\\Desktop\\\\Github\\\\ceds-cigar\\\\pycigar\\\\data\\\\701_5min_disag_noise\\\\701\\\\LS_shorten\"\n",
    "names = [name[:-4] for name in file_names]\n",
    "file_names = file_names\n",
    "batch = 5\n",
    "name_data = names\n",
    "load_data = []\n",
    "total_round_batch = len(names)//batch\n",
    "print(total_round_batch)\n",
    "for i in range(total_round_batch):\n",
    "    print(i, end=\" \")                                                       \n",
    "    batch_names = names[i*batch:i*batch+batch]\n",
    "    batch_file_names = file_names[i*batch:i*batch+batch]\n",
    "    batch_order = []\n",
    "    for name in batch_names:\n",
    "        batch_order.append(load_df.loc[name.lower()]['kW'])\n",
    "    load_gen = LoadGenerator(['{}/{}'.format(output_dir, name) for name in batch_file_names], input_time='15T', output_time='1S', order=batch_order)\n",
    "    load = load_gen.generate_load(batch_order)\n",
    "    load_data.extend(load)\n",
    "batch_names = names[(i+1)*batch:]\n",
    "batch_file_names = file_names[(i+1)*batch:]\n",
    "batch_order = []\n",
    "for name in batch_names:\n",
    "    batch_order.append(load_df.loc[name.lower()]['kW'])\n",
    "load_gen = LoadGenerator(['{}/{}'.format(output_dir, name) for name in batch_file_names], input_time='15T', output_time='1S', order=batch_order)\n",
    "load = load_gen.generate_load(batch_order)\n",
    "load_data.extend(load)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "for a in load_gen.em_mu:\n",
    "  \n",
    "    plt.plot(a)\n",
    "plt.legend(['a', 'b', 'c', 'd'])\n",
    "plt.ylabel('watts')\n",
    "plt.xlabel('arbitrary time unit')\n",
    "plt.title('xs')\n",
    "fig = plt.figure()\n",
    "for b in load_gen.em_x:\n",
    "    plt.plot(b)\n",
    "plt.title('mus')\n",
    "order = [4.67, 4.71, 4.76, 4.96]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hi = load_gen.generate_load(order)\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "for h in hi:\n",
    "    plt.plot(h)\n",
    "plt.title('generated profiles')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('watts (?)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import splev, splrep\n",
    "from pycigar.utils.data_generation.load.src.cdf import make_cdf\n",
    "\n",
    "\n",
    "def make_pdf(dist, params, size=10000):\n",
    "    \"\"\"Generate distributions's Probability Distribution Function \"\"\"\n",
    "    # Separate parts of parameters\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "\n",
    "    # Get same start and end points of distribution\n",
    "    start = dist.ppf(0.01, *arg, loc=loc,\n",
    "                     scale=scale) if arg else dist.ppf(0.01, loc=loc, scale=scale)\n",
    "    end = dist.ppf(0.99, *arg, loc=loc,\n",
    "                   scale=scale) if arg else dist.ppf(0.99, loc=loc, scale=scale)\n",
    "\n",
    "    # Build PDF and turn into pandas Series\n",
    "    x = np.linspace(start, end, size)\n",
    "    y = dist.pdf(x, loc=loc, scale=scale, *arg)\n",
    "    pdf = pd.Series(y, x)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def normalize_data(time_series, order):\n",
    "    pdfs = []\n",
    "    pdf_std = []\n",
    "\n",
    "    for file in time_series:\n",
    "        # Make PDF with best params\n",
    "        params = st.norm.fit(file)\n",
    "      \n",
    "        pdf = make_pdf(st.norm, params)  # mean and standard deviation\n",
    "        pdf_std.append(params[1])\n",
    "        pdfs.append(pdf)\n",
    "        \n",
    "    return pdfs, pdf_std\n",
    "\n",
    "\n",
    "def generate_polynomial(pdfs, order, std_of_nonnormal_pdfs):\n",
    "    \"\"\"\n",
    "    Fits a curve to standard deviation of the load profiles\n",
    "    Saves this curve to a pickle file\n",
    "    Plots curve\n",
    "    \"\"\"\n",
    "    # must be ordered on x-coordinates to use splrep \n",
    "    zipped_lists = zip(order, std_of_nonnormal_pdfs)\n",
    "    sorted_pairs = sorted(zipped_lists)\n",
    "    tuples = zip(*sorted_pairs)\n",
    "    list1, list2 = [ list(tuple) for tuple in  tuples]\n",
    "   \n",
    "    spl = splrep(list1, list2)\n",
    "    return spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_initial_data(input_file, output_time):\n",
    "    # Called by user\n",
    "    \"\"\" \n",
    "    Returns contents of input CSV files as different output time sequences\n",
    "\n",
    "    Args: \n",
    "    input_file (list of strings) - CSV file names \n",
    "        ex. ['7_MWp_P.csv', '10_MWp_P.csv', '12_MWp_P.csv', '19_MWp_P.csv']\n",
    "    input_time (string) - Input time sequence \n",
    "        ex. '1S'\n",
    "    output_time (list of strings)- Output time sequences \n",
    "        ex. ['1S', '10S', '30S']\n",
    "    order (list of integers) -  MWp for each file \n",
    "        ex. [7, 10, 12, 19]\n",
    "\n",
    "    \"\"\"\n",
    "    ff = []\n",
    "    fdd = []\n",
    "    tss = []\n",
    "    for n in range(len(output_time)):\n",
    "        f, ts = read_files(input_file, output_time[n])\n",
    "        ff.append(f)\n",
    "       \n",
    "        tss.append(ts)\n",
    "    return ff[0],tss[0]\n",
    "\n",
    "\n",
    "def read_files(input_file, output_time):\n",
    "    # User does not call\n",
    "\n",
    "    \"\"\" \n",
    "    Reads the input CSV files and resamples/diffs\n",
    "    Returns data in different forms\n",
    "\n",
    "    Args: \n",
    "    input_file (list of strings) - CSV file names \n",
    "        ex. ['7_MWp_P.csv', '10_MWp_P.csv', '12_MWp_P.csv', '19_MWp_P.csv']\n",
    "    output_time (list of strings)- Output time sequences \n",
    "        ex. ['1S', '10S', '30S']\n",
    "\n",
    "    \"\"\"\n",
    "    file = [] # series from csv file\n",
    "    file_diff = [] # resampled data\n",
    "    time_series = [] # resampled data as a series\n",
    "\n",
    "    for n in range(len(input_file)):\n",
    "        file.append(pd.read_csv(input_file[n], index_col = 0, header = None,names=['P'], parse_dates=True ,infer_datetime_format=True))\n",
    "#         print(file[n].resample(output_time).pad())\n",
    "#         print(file[n].resample(output_time).mean().pad().diff(1))\n",
    "        file_diff.append(file[n].resample(output_time).mean().pad().diff(1).dropna())\n",
    "        \n",
    "        time_series.append(file_diff[n].iloc[:,0])\n",
    "\n",
    "    return file, time_series\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_mean_reversion_rate(files, output_time, input_time, order, spl):\n",
    "    \"\"\"\n",
    "    Finds the mean reversion rate\n",
    "\n",
    "    Args: \n",
    "    files (list of DataFrames)\n",
    "    input_time (string) - represents in the input time series, ex. '1S'\n",
    "    output_time (string) - represents the output time series, ex. '1S'\n",
    "    order (list) - loading levels\n",
    "    \"\"\"\n",
    "\n",
    "    # x(t) profile\n",
    "    mrr = []\n",
    "    em_mu = []\n",
    "    em_x = []\n",
    "    em_Y = []\n",
    "    index_vals = []\n",
    "    meaned_data = []\n",
    "    orig_data = []\n",
    "\n",
    "    for k in range(len(files)):\n",
    "        #print(files[k].iloc[:10, :])\n",
    "        xs = files[k].resample(output_time).mean().pad()\n",
    "        meaned_data.append(xs)\n",
    "        orig_data.append(files[k])\n",
    "       \n",
    "\n",
    "    for n in range(len(meaned_data)):\n",
    "      \n",
    "        mu = orig_data[n].resample(input_time, label='right').mean().resample(output_time).pad()\n",
    "      #  print(len(mu), len(xs))\n",
    "        print(mu)\n",
    "        em_mu.append(mu)\n",
    "\n",
    "        # x profile\n",
    "        offset = len(xs) - len(mu)\n",
    "        x = meaned_data[n].pad().iloc[:len(meaned_data[n])-offset, :]\n",
    "   \n",
    "        index_vals.append(x.index.array)\n",
    "        em_x.append(x)\n",
    "\n",
    "        # Forming the Y's (contingent on std_dev)\n",
    "        Y = np.array([])\n",
    "        np_x = x.to_numpy()\n",
    "        np_mu_10 = mu.to_numpy()\n",
    "\n",
    "        std_dev = splev(order[n], spl)\n",
    "      \n",
    "\n",
    "        for i in range(len(x)):\n",
    "            Y = np.append(Y, (np_mu_10[i][0] - np_x[i][0]) / (std_dev**2))\n",
    "\n",
    "        em_Y.append(Y)\n",
    "     \n",
    "        # Mean reversion rate\n",
    "        num = 0\n",
    "        denom = 0\n",
    "        for j in range(len(x)-1):\n",
    "            num += Y[j] * (np_x[j+1][0] - np_mu_10[j+1][0])\n",
    "            denom += Y[j] * (np_x[j][0] - np_mu_10[j][0])\n",
    "        mean_rev_rate = -np.log(num/denom)\n",
    "        mrr.append(mean_rev_rate)\n",
    "\n",
    "    for i in range(len(em_mu)):\n",
    "        em_mu[i] = em_mu[i].to_numpy()\n",
    "        em_x[i] = em_x[i].to_numpy()\n",
    "\n",
    "    return mrr, em_mu, em_x, index_vals, meaned_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff,  tss = read_initial_data(new_file, ['1S'])\n",
    "order = [4.67, 4.71, 4.76, 4.96]\n",
    "output_time = '1S'\n",
    "input_time = '15T'\n",
    "#print(tss)\n",
    "pdfs, std_of_nonnormal_pdfs = normalize_data(tss, order)\n",
    "spl = generate_polynomial(pdfs, order, std_of_nonnormal_pdfs)\n",
    "\n",
    "mrr, em_mu, em_x, index_vals, meaned_data = \\\n",
    "    generate_mean_reversion_rate(ff, output_time, input_time, order, spl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = ff[0].resample(input_time, label='right').mean().resample(output_time).pad()\n",
    "# temp2 = temp.iloc[:, :]\n",
    "# temp2.index.name = 'hey'\n",
    "# print(temp2)\n",
    "# temp3 = ff[0].resample(output_time).mean().pad()\n",
    "# temp4 = temp3.iloc[600:, :]\n",
    "# temp4.index.name = 'hi'\n",
    "\n",
    "# temp4.iloc[300:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = load_gen.generate_load(dss_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "for i in out:\n",
    "    plt.figure()\n",
    "    plt.plot(i/10**6) #convert to watts\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
