{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the effects of PyCIGAR hyperparameters on training and results\n",
    "\n",
    "The goal of this notebook is to gain intuition on the impact of the different hyperparameters currently specified to train a PPO agent in PyCIGAR.\n",
    "\n",
    "Fixed settings in this experiment:\n",
    "- PPO algorithm\n",
    "- `ieee37busdata network` and load profile\n",
    "- tracked device: `inverter_s701a`\n",
    "- discrete single actions\n",
    "- `CentralControlPVInverterEnv` environment\n",
    "\n",
    "\n",
    "Hyperparameters identified:\n",
    "- discount factor $\\gamma$\n",
    "- train batch size\n",
    "- depth of NN\n",
    "- widths of NN layers\n",
    "- lr (or lr schedule)\n",
    "- loss factors (penalties)\n",
    "    - oscillation\n",
    "    - action change\n",
    "    - deviation from the initial command\n",
    "    \n",
    "    \n",
    "\n",
    "Until now, mostly qualitative results were obtained, mostly by looking at the graphs of voltage, $y$ value, injected power and actions taken by a tracked device over the course of a test simulation. In order to have objective grounds on which we can compare different solutions, we need quantitative results. Some statistics that reflect different aspects of both the solutions and the training processes are listed in the next section.\n",
    "\n",
    "## Statistics that summarize a training\n",
    "\n",
    "foreach epoch: \n",
    "    - number of actions taken\n",
    "    - average magnitude of the actions\n",
    "    - total reward\n",
    "    - time of earliest action\n",
    "    - average Shannon entropy of the action distribution\n",
    "\n",
    "- epoch at which the policy does not change anymore\n",
    "- average runtime of an epoch\n",
    "\n",
    "\n",
    "An additional qualitative result could be a GIF of the curves over epochs\n",
    "\n",
    "\n",
    "## Methods to understand hyperparameters\n",
    "\n",
    "Some methods that come to mind to obtain an intuition are:\n",
    "\n",
    "- try extreme values, then compare statistics\n",
    "- change independently: plot statistics\n",
    "- bayesian optimization with statistics for objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.tune.registry import register_env\n",
    "from pycigar.utils.registry import make_create_env\n",
    "from pycigar.utils.input_parser import input_parser\n",
    "\n",
    "import gym\n",
    "gym.logger.set_level(40) # remove gym warnings\n",
    "from ray.tune import JupyterNotebookReporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_params = input_parser('ieee37busdata')\n",
    "pycigar_params = {\"exp_tag\": \"cooperative_multiagent_ppo\",\n",
    "                  \"env_name\": \"CentralControlPVInverterEnv\",\n",
    "                  \"sim_params\": sim_params,\n",
    "                  \"simulator\": \"opendss\",\n",
    "                  \"tracking_ids\": ['inverter_s701a']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 17:01:21,762\tINFO resource_spec.py:212 -- Starting Ray with 31.15 GiB memory available for workers and up to 15.58 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered env CentralControlPVInverterEnv-v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 17:01:22,285\tINFO services.py:1078 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '128.3.28.231',\n",
       " 'redis_address': '128.3.28.231:37077',\n",
       " 'object_store_address': '/tmp/ray/session_2020-02-26_17-01-21_740330_17115/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-02-26_17-01-21_740330_17115/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-02-26_17-01-21_740330_17115'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_env, env_name, create_test_env, test_env_name = make_create_env(params=pycigar_params, version=0)\n",
    "register_env(env_name, create_env)\n",
    "register_env(test_env_name, create_test_env)\n",
    "\n",
    "test_env = create_test_env()\n",
    "obs_space = test_env.observation_space\n",
    "act_space = test_env.action_space\n",
    "\n",
    "print(\"Registered env\", env_name)\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coop_train_fn(config, reporter):\n",
    "    agent1 = PPOTrainer(env=env_name, config=config)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        result = agent1.train()\n",
    "        reporter(**result)\n",
    "        phase1_time = result[\"timesteps_total\"]\n",
    "\n",
    "\n",
    "        checkpoint = trainer.save()\n",
    "        print(\"Checkpoint saved at\", checkpoint)\n",
    "        state = agent1.save('~/ray_results/checkpoint')\n",
    "        done = False\n",
    "        start_time = time.time()\n",
    "        obs = test_env.reset()\n",
    "        reward = 0\n",
    "        while not done:\n",
    "            act = agent1.compute_action(obs)\n",
    "            obs, r, done, _ = test_env.step(act)\n",
    "            reward += r\n",
    "        end_time = time.time()\n",
    "        ep_time = end_time-start_time\n",
    "        print(\"\\n Episode time is\", ep_time)\n",
    "\n",
    "\n",
    "        #    test_env.plot(pycigar_params['exp_tag'], test_env_name, i+1, reward)\n",
    "    # save the params of agent\n",
    "    # state = agent1.save()\n",
    "    # stop the agent\n",
    "    agent1.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"gamma\": 0.5,\n",
    "    'lr': 5e-04,\n",
    "    'sample_batch_size': 50,\n",
    "    'train_batch_size': 500,\n",
    "    # 'lr_schedule': [[0, 5e-04], [12000, 5e-04], [13500, 5e-05]],\n",
    "\n",
    "    'num_workers': 7,\n",
    "    'num_cpus_per_worker': 1,\n",
    "    'num_cpus_for_driver': 1,\n",
    "    'num_envs_per_worker': 1,\n",
    "    \n",
    "    'evaluation_interval': 2,\n",
    "    'evaluation_num_episodes': 1,\n",
    "    \"evaluation_config\": {\n",
    "        # Example: overriding env_config, exploration, etc:\n",
    "        # \"env_config\": {...},\n",
    "        \"explore\": False,\n",
    "        \"env_name\": test_env_name\n",
    "    },\n",
    "    \n",
    "    'log_level': 'INFO',\n",
    "\n",
    "    'model': {\n",
    "        'fcnet_activation': 'tanh',\n",
    "        'fcnet_hiddens': [128, 64, 32],\n",
    "        'free_log_std': False,\n",
    "        'vf_share_layers': True,\n",
    "        'use_lstm': False,\n",
    "        'state_shape': None,\n",
    "        'framestack': False,\n",
    "        'zero_mean': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# call tune.run() to run the coop_train_fn() with the config() above\n",
    "reporter = JupyterNotebookReporter(overwrite=False, max_progress_rows=20)\n",
    "tune.run(coop_train_fn, config=config, progress_reporter=reporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH alex@gigteam.lbl.gov GIG team",
   "language": "",
   "name": "rik_ssh_alex_gigteam_lbl_gov_gigteam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
